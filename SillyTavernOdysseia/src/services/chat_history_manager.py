#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ChatHistoryç®¡ç†æ¨¡å—

è´Ÿè´£ç»´æŠ¤å’Œç®¡ç†èŠå¤©å†å²ï¼Œå¤„ç†æç¤ºè¯æ‹¼æ¥ï¼ŒåŒ…æ‹¬ï¼š
- ç”¨æˆ·ä¸AIçš„å¯¹è¯å†å²
- "mode": "always"çš„ä¸–ç•Œä¹¦æ¡ç›®
- "position": "in-chat"çš„é¢„è®¾æ¡ç›®
- ä»¥OpenAIæ ¼å¼çš„messageè¿›è¡Œå­˜å‚¨

ä¸»è¦åŠŸèƒ½ï¼š
1. ç®¡ç†å®æ—¶æ›´æ–°çš„èŠå¤©å†å²
2. å¤„ç†ä¸–ç•Œä¹¦å’Œé¢„è®¾çš„åŠ¨æ€æ‹¼æ¥
3. è§’è‰²æ˜ å°„å’Œæ¶ˆæ¯æ ¼å¼åŒ–
4. æ”¯æŒæ¡ä»¶è§¦å‘çš„ä¸–ç•Œä¹¦æ¡ç›®
"""

from __future__ import annotations

import re
from typing import Any, Dict, List, Optional, Set, Union
from dataclasses import dataclass, field
from enum import Enum
import sys
from pathlib import Path

# æ·»åŠ utilsç›®å½•åˆ°è·¯å¾„ï¼Œå¯¼å…¥å®å¤„ç†å™¨
sys.path.insert(0, str(Path(__file__).parent.parent / "utils"))
from macro_processor import MacroProcessor


class MessageRole(Enum):
    """æ¶ˆæ¯è§’è‰²æšä¸¾"""
    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"


@dataclass 
class ContentPart:
    """å†…å®¹éƒ¨åˆ†ï¼ŒåŒ…å«å†…å®¹å’Œæ¥æºæ ‡ç­¾"""
    content: str
    source_type: str  # 'preset', 'char', 'world', 'conversation'
    source_id: str    # å…·ä½“æ ‡è¯†ç¬¦
    source_label: Optional[str] = None  # å¯é€‰çš„æ¥æºæ ‡ç­¾ï¼ˆç”¨äºè°ƒè¯•æ˜¾ç¤ºï¼‰


@dataclass
class ChatMessage:
    """èŠå¤©æ¶ˆæ¯æ•°æ®ç±» - æ”¯æŒå¤šå†…å®¹éƒ¨åˆ†å’Œæ¥æºæ ‡è®°"""
    role: MessageRole
    # æ”¯æŒå¤šä¸ªå†…å®¹éƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†æœ‰è‡ªå·±çš„æ¥æºæ ‡è®°
    content_parts: List[ContentPart] = field(default_factory=list)
    # å‘åå…¼å®¹çš„å•ä¸€å†…å®¹å­—æ®µ
    content: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†ï¼Œç¡®ä¿å‘åå…¼å®¹"""
        # å¦‚æœåªæœ‰contentå­—æ®µï¼Œè½¬æ¢ä¸ºcontent_parts
        if self.content and not self.content_parts:
            # å°è¯•ä»metadataæ¨æ–­æ¥æº
            source_type = "temp"
            source_id = "unknown"
            
            if "source" in self.metadata:
                if "world_book" in self.metadata["source"]:
                    source_type = "world"
                    source_id = f"world_{self.metadata.get('entry_id', 'unknown')}"
                elif "preset" in self.metadata["source"]:
                    source_type = "preset"
                    source_id = f"preset_{self.metadata.get('identifier', 'unknown')}"
                elif self.metadata["source"] in ["user", "assistant"]:
                    source_type = "conversation"
                    source_id = self.metadata["source"]
            
            self.content_parts = [ContentPart(
                content=self.content,
                source_type=source_type,
                source_id=source_id
            )]
    
    def add_content_part(self, content: str, source_type: str, source_id: str, source_label: str = None):
        """æ·»åŠ å†…å®¹éƒ¨åˆ†"""
        self.content_parts.append(ContentPart(
            content=content,
            source_type=source_type,
            source_id=source_id,
            source_label=source_label
        ))
    
    def get_merged_content(self) -> str:
        """è·å–åˆå¹¶åçš„å†…å®¹ï¼ˆä»…åœ¨æœ€ç»ˆè¾“å‡ºæ—¶ä½¿ç”¨ï¼‰"""
        if self.content:
            return self.content
        return "\n\n".join(part.content for part in self.content_parts)
    
    def has_multiple_sources(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæ¥æº"""
        return len(self.content_parts) > 1
    
    def to_openai_format(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºæ‰©å±•çš„OpenAI APIæ ¼å¼ï¼Œä¿ç•™æ‰€æœ‰æ¥æºä¿¡æ¯"""
        # åŸºç¡€æ ¼å¼
        result = {
            "role": self.role.value,
            "content": self.get_merged_content()  # åˆå¹¶åçš„å†…å®¹ï¼Œå…¼å®¹æ ‡å‡†OpenAI API
        }
        
        # æ‰©å±•å­—æ®µï¼šå¤šå†…å®¹éƒ¨åˆ†å’Œæ¥æºä¿¡æ¯
        if self.content_parts:
            result["_content_parts"] = [
                {
                    "content": part.content,
                    "source_type": part.source_type,
                    "source_id": part.source_id,
                    "source_label": part.source_label
                }
                for part in self.content_parts
            ]
            
            # æ¥æºç±»å‹åˆ—è¡¨ï¼ˆç”¨äºå¿«é€Ÿæ£€æŸ¥ï¼‰
            result["_source_types"] = list({part.source_type for part in self.content_parts})
            
        return result
    
    def get_primary_source_type(self) -> str:
        """è·å–ä¸»è¦æ¥æºç±»å‹ï¼ˆç”¨äºå‘åå…¼å®¹ï¼Œç°åœ¨ä¸»è¦ç”¨äºå•å†…å®¹æ¶ˆæ¯ï¼‰"""
        if not self.content_parts:
            return "temp"
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªå†…å®¹éƒ¨åˆ†ï¼Œç›´æ¥è¿”å›å…¶ç±»å‹
        if len(self.content_parts) == 1:
            return self.content_parts[0].source_type
        
        # å¤šå†…å®¹éƒ¨åˆ†æ—¶ï¼Œä¼˜å…ˆçº§ï¼špreset > world > char > conversation > temp (æƒé™å±‚çº§)
        # æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•ç°åœ¨ä¸»è¦ç”¨äºå‘åå…¼å®¹ï¼Œå®é™…å®å¤„ç†å·²æ”¹ä¸ºåˆ†åˆ«å¤„ç†æ¯ä¸ªéƒ¨åˆ†
        priority = {"preset": 4, "world": 3, "char": 2, "conversation": 1, "temp": 0}
        
        primary_type = max(
            (part.source_type for part in self.content_parts),
            key=lambda x: priority.get(x, 0)
        )
        
        return primary_type
    
    def get_content_by_source(self, source_type: str) -> List[str]:
        """è·å–æŒ‡å®šæ¥æºç±»å‹çš„æ‰€æœ‰å†…å®¹"""
        return [
            part.content 
            for part in self.content_parts 
            if part.source_type == source_type
        ]


@dataclass
class WorldBookEntry:
    """ä¸–ç•Œä¹¦æ¡ç›®æ•°æ®ç±»"""
    id: int
    name: str
    enabled: bool  # å‘åå…¼å®¹çš„å¸ƒå°”å€¼ï¼Œè¿è¡Œæ—¶åŠ¨æ€è®¡ç®—
    mode: str  # "always", "conditional", "vector"
    position: str  # "user", "assistant", "system", "before_char", "after_char"
    keys: List[str]
    content: str
    depth: Optional[int] = None
    order: int = 100  # ç»Ÿä¸€ä½¿ç”¨orderå­—æ®µï¼Œæ¥æºäºinsertion_order
    code_block: Optional[str] = None  # æ¡ç›®è§¦å‘æ—¶æ‰§è¡Œçš„ä»£ç å—
    
    # åŠ¨æ€enabledæ”¯æŒ
    enabled_expression: Any = None  # å­˜å‚¨åŸå§‹enabledå€¼ï¼ˆå¸ƒå°”å€¼ã€å®æˆ–Pythonè¡¨è¾¾å¼ï¼‰
    enabled_cached: Optional[bool] = None  # ç¼“å­˜è®¡ç®—ç»“æœ


@dataclass
class PresetPrompt:
    """é¢„è®¾æç¤ºè¯æ•°æ®ç±»"""
    identifier: str
    name: str
    enabled: bool  # å‘åå…¼å®¹çš„å¸ƒå°”å€¼ï¼Œè¿è¡Œæ—¶åŠ¨æ€è®¡ç®—
    role: str  # "system", "user", "assistant"
    position: str  # "relative", "in-chat"
    content: Optional[str] = None
    depth: Optional[int] = None
    order: Optional[int] = None  # ç»Ÿä¸€ä½¿ç”¨orderå­—æ®µï¼Œæ¥æºäºinjection_order
    code_block: Optional[str] = None  # é¢„è®¾å¯ç”¨æ—¶æ‰§è¡Œçš„ä»£ç å—
    
    # åŠ¨æ€enabledæ”¯æŒ
    enabled_expression: Any = None  # å­˜å‚¨åŸå§‹enabledå€¼ï¼ˆå¸ƒå°”å€¼ã€å®æˆ–Pythonè¡¨è¾¾å¼ï¼‰
    enabled_cached: Optional[bool] = None  # ç¼“å­˜è®¡ç®—ç»“æœ


class ChatHistoryManager:
    """èŠå¤©å†å²ç®¡ç†å™¨"""
    
    def __init__(self):
        self.chat_history: List[ChatMessage] = []
        self.world_book_entries: List[WorldBookEntry] = []
        self.preset_prompts: List[PresetPrompt] = []
        self.triggered_entries: Set[int] = set()  # å·²è§¦å‘çš„ä¸–ç•Œä¹¦æ¡ç›®ID
        self.character_data: Dict[str, Any] = {}  # å­˜å‚¨è§’è‰²æ•°æ®ç”¨äºæ„å»ºæœ€ç»ˆæç¤ºè¯
        self.persona_data: Dict[str, Any] = {}    # å­˜å‚¨ç©å®¶å¡æ•°æ®
        self.enable_macros: bool = True           # æ˜¯å¦å¯ç”¨å®å¤„ç†
        self._macro_processor: Optional[MacroProcessor] = None  # æŒä¹…çš„å®å¤„ç†å™¨å®ä¾‹
        
    def load_world_book(self, world_book_data: Dict[str, Any]) -> None:
        """åŠ è½½ä¸–ç•Œä¹¦æ•°æ®"""
        if not world_book_data or "entries" not in world_book_data:
            return
            
        self.world_book_entries = []
        for entry_data in world_book_data["entries"]:
            # æå–æ’åºå­—æ®µï¼šä¼˜å…ˆä½¿ç”¨insertion_orderï¼Œå…¶æ¬¡æ˜¯extensionsä¸­çš„positionï¼Œæœ€åæ˜¯é»˜è®¤å€¼
            order = entry_data.get("insertion_order")
            if order is None and "extensions" in entry_data:
                order = entry_data["extensions"].get("position")
            if order is None:
                order = 100
            
            # æå–enabledè¡¨è¾¾å¼
            enabled_expr = entry_data.get("enabled", True)
            
            entry = WorldBookEntry(
                id=entry_data.get("id", 0),
                name=entry_data.get("name", ""),
                enabled=True,  # åˆå§‹å€¼ï¼Œè¿è¡Œæ—¶åŠ¨æ€è®¡ç®—
                mode=entry_data.get("mode", "conditional"),
                position=entry_data.get("position", "before_char"),
                keys=entry_data.get("keys", []),
                content=entry_data.get("content", ""),
                depth=entry_data.get("depth"),
                order=order,
                code_block=entry_data.get("code_block"),  # ä»£ç å—
                enabled_expression=enabled_expr,  # ä¿å­˜åŸå§‹è¡¨è¾¾å¼
                enabled_cached=None
            )
            self.world_book_entries.append(entry)
    
    def load_presets(self, preset_data: Dict[str, Any]) -> None:
        """åŠ è½½é¢„è®¾æ•°æ®"""
        if not preset_data or "prompts" not in preset_data:
            return
            
        self.preset_prompts = []
        for prompt_data in preset_data["prompts"]:
            # æå–enabledè¡¨è¾¾å¼å’Œæ’åºå­—æ®µ
            enabled_expr = prompt_data.get("enabled", True)
            order = prompt_data.get("injection_order")
            if order is None:
                order = prompt_data.get("order")
                
            prompt = PresetPrompt(
                identifier=prompt_data.get("identifier", ""),
                name=prompt_data.get("name", ""),
                enabled=True,  # åˆå§‹å€¼ï¼Œè¿è¡Œæ—¶åŠ¨æ€è®¡ç®—
                role=prompt_data.get("role", "system"),
                position=prompt_data.get("position", "relative"),
                content=prompt_data.get("content", ""),  # ç¡®ä¿åŒ…å«ç©ºcontent
                depth=prompt_data.get("depth"),
                order=order,
                code_block=prompt_data.get("code_block"),  # ä»£ç å—
                enabled_expression=enabled_expr,  # ä¿å­˜åŸå§‹è¡¨è¾¾å¼
                enabled_cached=None
            )
            self.preset_prompts.append(prompt)
    
    def _map_position_to_role(self, position: str) -> MessageRole:
        """å°†positionæ˜ å°„åˆ°MessageRole"""
        position_role_map = {
            "assistant": MessageRole.ASSISTANT,
            "user": MessageRole.USER,
            "system": MessageRole.SYSTEM,
            "before_char": MessageRole.SYSTEM,
            "after_char": MessageRole.SYSTEM
        }
        return position_role_map.get(position, MessageRole.SYSTEM)
    
    def _get_role_priority(self, role: str) -> int:
        """è·å–roleçš„ä¼˜å…ˆçº§ï¼ˆæŒ‰æ¬¡åºè§„åˆ™ï¼šassistantã€userã€systemï¼‰"""
        role_priority = {
            "assistant": 0,  # æœ€é«˜ä¼˜å…ˆçº§
            "user": 1,
            "system": 2      # æœ€ä½ä¼˜å…ˆçº§
        }
        return role_priority.get(role, 2)  # é»˜è®¤ä¸ºsystemä¼˜å…ˆçº§
    
    def _sort_by_order_rules(self, entries: List, get_depth_func, get_order_func, get_role_func, get_internal_order_func):
        """
        æŒ‰ç…§æ¬¡åºè§„åˆ™æ’åºï¼š
        1. å…ˆçœ‹æ·±åº¦ï¼ˆdepthï¼‰
        2. å†çœ‹é¡ºåºï¼ˆorderï¼‰ï¼Œæ•°å­—å°çš„è¶Šé å‰
        3. å†çœ‹roleï¼ŒæŒ‰assistantã€userã€systemé¡ºåº
        4. å¦‚æœå‰é¢éƒ½ä¸€æ ·ï¼Œåˆ™æŒ‰ç…§å†…éƒ¨æ’åˆ—æ¬¡åºï¼Œè¶Šé å‰çš„è¶Šåœ¨æç¤ºè¯ä¸‹é¢
        """
        def sort_key(entry):
            depth = get_depth_func(entry) or 0
            order = get_order_func(entry) or 100
            role = get_role_func(entry) or "system"
            internal_order = get_internal_order_func(entry)
            
            # æ³¨æ„ï¼š
            # - depthå¤§çš„è¦é å‰ï¼Œæ‰€ä»¥å–è´Ÿå€¼è®©å¤§çš„æ’åœ¨å‰é¢  
            # - orderå°çš„è¦é å‰ï¼Œæ‰€ä»¥ä¸å–è´Ÿå€¼è®©å°çš„æ’åœ¨å‰é¢
            return (-depth, order, self._get_role_priority(role), internal_order)
        
        return sorted(entries, key=sort_key)
    
    def clear_enabled_cache(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰enabledç¼“å­˜ï¼Œé€šå¸¸åœ¨æ–°å¯¹è¯è½®æ¬¡å¼€å§‹æ—¶è°ƒç”¨"""
        for entry in self.world_book_entries:
            entry.enabled_cached = None
        for prompt in self.preset_prompts:
            prompt.enabled_cached = None
    
    def _is_definitely_disabled(self, item: Union[WorldBookEntry, PresetPrompt]) -> bool:
        """åˆ¤æ–­æ¡ç›®æ˜¯å¦ç¡®å®šè¢«ç¦ç”¨ï¼ˆenabled=falseï¼‰"""
        expression = getattr(item, 'enabled_expression', None)
        if expression is None:
            expression = item.enabled
        
        # åªæœ‰æ˜ç¡®çš„falseæ‰ç®—"ç¡®å®šç¦ç”¨"
        return expression is False
    
    def _should_include_in_initial_build(self, item: Union[WorldBookEntry, PresetPrompt]) -> bool:
        """åˆ¤æ–­æ¡ç›®æ˜¯å¦åº”è¯¥åŒ…å«åœ¨åˆå§‹æ„å»ºä¸­ï¼ˆéç¡®å®šç¦ç”¨çš„éƒ½åŒ…å«ï¼‰"""
        return not self._is_definitely_disabled(item)
    
    def _evaluate_enabled(self, item: Union[WorldBookEntry, PresetPrompt]) -> bool:
        """è¯„ä¼°æ¡ç›®çš„enabledçŠ¶æ€ï¼ˆæ”¯æŒåŠ¨æ€è®¡ç®—ï¼‰"""
        # 1. æ£€æŸ¥ç¼“å­˜
        if item.enabled_cached is not None:
            return item.enabled_cached
        
        # 2. è·å–åŸå§‹è¡¨è¾¾å¼
        expression = getattr(item, 'enabled_expression', None)
        if expression is None:
            # å›é€€åˆ°åŸå§‹enabledå­—æ®µ
            expression = item.enabled
        
        # 3. æ ¹æ®ç±»å‹å¤„ç†
        try:
            if isinstance(expression, bool):
                result = expression
            elif isinstance(expression, str):
                if "{{" in expression and "}}" in expression:
                    # å®è¯­æ³•å¤„ç†ï¼ˆåŒ…æ‹¬{{python:expression}}ï¼‰
                    result = self._process_enabled_macro(expression)
                else:
                    # å‘åå…¼å®¹ï¼šè‡ªåŠ¨è½¬æ¢ä¸º{{python:expr}}æ ¼å¼
                    python_macro = f"{{{{python:{expression}}}}}"
                    result = self._process_enabled_macro(python_macro)
            else:
                # å…¶ä»–ç±»å‹é»˜è®¤è½¬æ¢ä¸ºå¸ƒå°”å€¼
                result = bool(expression)
        except Exception as e:
            # é”™è¯¯æ—¶é»˜è®¤ä¸ºFalseï¼Œè®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æµç¨‹
            print(f"âš ï¸  enabledè¯„ä¼°å¤±è´¥ ({item.name}): {e}")
            result = False
        
        # 4. ç¼“å­˜å¹¶è¿”å›ç»“æœ
        item.enabled_cached = bool(result)
        return item.enabled_cached
    
    def _process_enabled_macro(self, expression: str) -> bool:
        """å¤„ç†å®è¯­æ³•çš„enabledè¡¨è¾¾å¼ï¼ˆç»Ÿä¸€ä½¿ç”¨å®å¤„ç†å™¨ï¼‰"""
        # ç»Ÿä¸€ä½¿ç”¨å®å¤„ç†å™¨ï¼ˆåŒ…æ‹¬{{python:}}ã€{{getvar::}}ç­‰æ‰€æœ‰å®ï¼‰
        if not hasattr(self, '_macro_processor') or self._macro_processor is None:
            macro_context = self._build_macro_context()
            self._macro_processor = MacroProcessor(macro_context)
        
        # å¤„ç†å®è¡¨è¾¾å¼
        result = self._macro_processor._process_string(expression)
        
        # å°è¯•å°†ç»“æœè½¬æ¢ä¸ºå¸ƒå°”å€¼
        if isinstance(result, str):
            result = result.strip().lower()
            if result in ('true', '1', 'yes', 'on'):
                return True
            elif result in ('false', '0', 'no', 'off', ''):
                return False
            else:
                # å°è¯•è½¬æ¢ä¸ºæ•°å­—ï¼Œéé›¶ä¸ºTrue
                try:
                    return float(result) != 0
                except (ValueError, TypeError):
                    return bool(result)
        
        return bool(result)
    
    def _evaluate_enabled_with_sandbox(self, item: Union[WorldBookEntry, PresetPrompt], sandbox=None) -> bool:
        """ä½¿ç”¨æ²™ç›’è¯„ä¼°æ¡ç›®çš„enabledçŠ¶æ€ï¼ˆæ”¯æŒåŠ¨æ€è®¡ç®—å’Œå˜é‡ä¾èµ–ï¼‰"""
        # 1. æ£€æŸ¥ç¼“å­˜
        if item.enabled_cached is not None:
            return item.enabled_cached
        
        # 2. è·å–åŸå§‹è¡¨è¾¾å¼
        expression = getattr(item, 'enabled_expression', None)
        if expression is None:
            # å›é€€åˆ°åŸå§‹enabledå­—æ®µ
            expression = item.enabled
        
        # 3. æ ¹æ®ç±»å‹å¤„ç†
        try:
            if isinstance(expression, bool):
                result = expression
            elif isinstance(expression, str):
                if "{{" in expression and "}}" in expression:
                    # å®è¯­æ³•å¤„ç† - ä¼˜å…ˆä½¿ç”¨æ²™ç›’ï¼Œå›é€€åˆ°ä¼ ç»Ÿå®å¤„ç†å™¨
                    if sandbox:
                        result = self._process_enabled_macro_with_sandbox(expression, sandbox)
                    else:
                        result = self._process_enabled_macro(expression)
                else:
                    # å‘åå…¼å®¹ï¼šè‡ªåŠ¨è½¬æ¢ä¸º{{python:expr}}æ ¼å¼
                    python_macro = f"{{{{python:{expression}}}}}"
                    if sandbox:
                        result = self._process_enabled_macro_with_sandbox(python_macro, sandbox)
                    else:
                        result = self._process_enabled_macro(python_macro)
            else:
                # å…¶ä»–ç±»å‹é»˜è®¤è½¬æ¢ä¸ºå¸ƒå°”å€¼
                result = bool(expression)
        except Exception as e:
            # é”™è¯¯æ—¶é»˜è®¤ä¸ºFalseï¼Œè®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æµç¨‹
            print(f"âš ï¸  enabledè¯„ä¼°å¤±è´¥ ({item.name}): {e}")
            result = False
        
        # 4. ç¼“å­˜å¹¶è¿”å›ç»“æœ
        item.enabled_cached = bool(result)
        return item.enabled_cached
    
    def _process_enabled_macro_with_sandbox(self, expression: str, sandbox) -> bool:
        """ä½¿ç”¨æ²™ç›’å¤„ç†enabledè¡¨è¾¾å¼ä¸­çš„å®"""
        try:
            # ä½¿ç”¨Pythonå®å¤„ç†å™¨å¤„ç†è¡¨è¾¾å¼ï¼Œä¼ å…¥æ²™ç›’
            processed = self._process_python_macros(expression, 'temp', sandbox)
            
            # å°è¯•å°†ç»“æœè½¬æ¢ä¸ºå¸ƒå°”å€¼
            if isinstance(processed, str):
                processed = processed.strip().lower()
                if processed in ('true', '1', 'yes', 'on'):
                    return True
                elif processed in ('false', '0', 'no', 'off', ''):
                    return False
                else:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å­—ï¼Œéé›¶ä¸ºTrue
                    try:
                        return float(processed) != 0
                    except (ValueError, TypeError):
                        return bool(processed)
            
            return bool(processed)
            
        except Exception as e:
            print(f"âš ï¸  æ²™ç›’enabledè¯„ä¼°å¤±è´¥: {e}")
            # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
            return self._process_enabled_macro(expression)
    
    def _execute_character_code_block(self) -> None:
        """æ‰§è¡Œè§’è‰²çš„code_blockï¼ˆè§’è‰²åŠ è½½æ—¶è°ƒç”¨ï¼‰"""
        if not self.character_data or "code_block" not in self.character_data:
            return
        
        code_block = self.character_data["code_block"]
        if not code_block or not code_block.strip():
            return
        
        print(f"ğŸ­ æ‰§è¡Œè§’è‰²ä»£ç å—: {self.character_data.get('name', 'Unknown')}")
        print(f"  ä»£ç : {code_block}")
        
        try:
            # ç¡®ä¿æœ‰å®å¤„ç†å™¨
            if not hasattr(self, '_macro_processor') or self._macro_processor is None:
                macro_context = self._build_macro_context()
                from macro_processor import MacroProcessor
                self._macro_processor = MacroProcessor(macro_context)
            
            # ä½¿ç”¨å®å¤„ç†å™¨æ‰§è¡ŒåŒ…å«Pythonä»£ç çš„å­—ç¬¦ä¸²
            wrapped_code = f"{{{{python:{code_block}}}}}"
            result = self._macro_processor._process_string(wrapped_code)
            print(f"âœ… è§’è‰²ä»£ç å—æ‰§è¡ŒæˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ è§’è‰²ä»£ç å—æ‰§è¡Œå¤±è´¥: {e}")
    
    def _execute_preset_code_blocks(self) -> None:
        """æ‰§è¡Œå¯ç”¨çš„é¢„è®¾ä»£ç å—ï¼ˆå·²åºŸå¼ƒï¼Œç°åœ¨é›†æˆåˆ°åŠ¨æ€æ„å»ºè¿‡ç¨‹ä¸­ï¼‰"""
        # è¿™ä¸ªæ–¹æ³•ç°åœ¨ä¸å†ä½¿ç”¨ï¼Œå› ä¸ºä»£ç å—æ‰§è¡Œå·²ç»é›†æˆåˆ°build_final_prompt_dynamicä¸­
        print("â„¹ï¸  _execute_preset_code_blockså·²è¢«åŠ¨æ€æ„å»ºæµç¨‹å–ä»£")

    def add_user_message(self, content: str) -> None:
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        message = ChatMessage(
            role=MessageRole.USER,
            content=content,
            metadata={"source": "user"}
        )
        self.chat_history.append(message)
        
        # æ£€æŸ¥å¹¶è§¦å‘æ¡ä»¶ä¸–ç•Œä¹¦æ¡ç›®
        self._check_conditional_world_book(content)
    
    def add_assistant_message(self, content: str) -> None:
        """æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯"""
        message = ChatMessage(
            role=MessageRole.ASSISTANT,
            content=content,
            metadata={"source": "assistant"}
        )
        self.chat_history.append(message)
    
    def _check_conditional_world_book(self, user_input: str) -> None:
        """æ£€æŸ¥å¹¶è§¦å‘æ¡ä»¶ä¸–ç•Œä¹¦æ¡ç›®"""
        for entry in self.world_book_entries:
            # æ¡ä»¶ä¸–ç•Œä¹¦åœ¨è§¦å‘æ—¶æ‰éœ€è¦æ£€æŸ¥enabledçŠ¶æ€
            if not self._should_include_in_initial_build(entry) or entry.mode != "conditional":
                continue
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            if self._matches_keywords(user_input, entry.keys):
                if entry.id not in self.triggered_entries:
                    self._trigger_world_book_entry(entry)
                    self.triggered_entries.add(entry.id)
    
    def _matches_keywords(self, text: str, keywords: List[str]) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ¹é…å…³é”®è¯"""
        text_lower = text.lower()
        for keyword in keywords:
            if keyword.lower() in text_lower:
                return True
        return False
    
    def _trigger_world_book_entry(self, entry: WorldBookEntry) -> None:
        """è§¦å‘ä¸–ç•Œä¹¦æ¡ç›®ï¼Œæ·»åŠ åˆ°èŠå¤©å†å²"""
        role = self._map_position_to_role(entry.position)
        
        message = ChatMessage(
            role=role,
            content=entry.content,
            metadata={
                "source": "world_book",
                "entry_id": entry.id,
                "entry_name": entry.name,
                "depth": entry.depth,
                "order": entry.order
            }
        )
        
        # æ ¹æ®depthæ’å…¥åˆ°é€‚å½“ä½ç½®
        if entry.depth and len(self.chat_history) >= entry.depth:
            insert_pos = len(self.chat_history) - entry.depth
            self.chat_history.insert(insert_pos, message)
        else:
            self.chat_history.append(message)
    
    def _get_always_world_book_messages(self) -> List[ChatMessage]:
        """è·å–modeä¸ºalwaysçš„ä¸–ç•Œä¹¦æ¶ˆæ¯"""
        # æ”¶é›†ç¬¦åˆæ¡ä»¶çš„æ¡ç›®ï¼ˆåˆå§‹åŒ…å«éç¡®å®šç¦ç”¨çš„ï¼‰
        always_entries = [entry for entry in self.world_book_entries 
                         if self._should_include_in_initial_build(entry) and entry.mode == "always"]
        
        # æŒ‰æ¬¡åºè§„åˆ™æ’åº
        if always_entries:
            # ä¸ºæ¯ä¸ªæ¡ç›®æ·»åŠ åŸå§‹é¡ºåºæ ‡è®°
            for i, entry in enumerate(always_entries):
                entry._original_order = i
            
            # æŒ‰æ¬¡åºè§„åˆ™æ’åº
            always_entries = self._sort_by_order_rules(
                always_entries,
                get_depth_func=lambda x: getattr(x, 'depth', None),
                get_order_func=lambda x: getattr(x, 'order', 100),
                get_role_func=lambda x: getattr(x, 'position', 'system'),
                get_internal_order_func=lambda x: getattr(x, '_original_order', 0)
            )
        
        # è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
        messages = []
        for entry in always_entries:
            role = self._map_position_to_role(entry.position)
            message = ChatMessage(
                role=role,
                content=entry.content,
                metadata={
                    "source": "world_book_always",
                    "entry_id": entry.id,
                    "entry_name": entry.name,
                    "depth": entry.depth,
                    "order": entry.order
                }
            )
            messages.append(message)
        return messages
    
    def _get_in_chat_preset_messages(self) -> List[ChatMessage]:
        """è·å–positionä¸ºin-chatçš„é¢„è®¾æ¶ˆæ¯"""
        messages = []
        for prompt in self.preset_prompts:
            if self._should_include_in_initial_build(prompt) and prompt.position == "in-chat" and prompt.content:
                role = MessageRole(prompt.role) if prompt.role in ["system", "user", "assistant"] else MessageRole.SYSTEM
                message = ChatMessage(
                    role=role,
                    content=prompt.content,
                    metadata={
                        "source": "preset_in_chat",
                        "identifier": prompt.identifier,
                        "depth": prompt.depth,
                        "order": prompt.order
                    }
                )
                messages.append(message)
        return messages
    
    def get_full_chat_history(self) -> List[ChatMessage]:
        """è·å–å®Œæ•´çš„èŠå¤©å†å²ï¼ŒåŒ…æ‹¬åŠ¨æ€æ‹¼æ¥çš„å†…å®¹"""
        full_history = []
        
        # 1. æ·»åŠ alwaysæ¨¡å¼çš„ä¸–ç•Œä¹¦æ¡ç›®
        always_messages = self._get_always_world_book_messages()
        full_history.extend(always_messages)
        
        # 2. æ·»åŠ in-chatä½ç½®çš„é¢„è®¾
        in_chat_presets = self._get_in_chat_preset_messages()
        
        # 3. å°†in-chaté¢„è®¾æŒ‰æ¬¡åºè§„åˆ™æ’åºåæ’å…¥åˆ°èŠå¤©å†å²ä¸­
        merged_history = self.chat_history.copy()
        
        # æŒ‰ç…§å®Œæ•´çš„æ¬¡åºè§„åˆ™æ’åºin-chaté¢„è®¾
        if in_chat_presets:
            # ä¸ºæ¯ä¸ªé¢„è®¾æ·»åŠ åŸå§‹é¡ºåºæ ‡è®°
            for i, preset in enumerate(in_chat_presets):
                preset.metadata["original_order"] = i
            
            # æŒ‰æ¬¡åºè§„åˆ™æ’åº
            sorted_presets = self._sort_by_order_rules(
                in_chat_presets,
                get_depth_func=lambda x: x.metadata.get("depth", 0),
                get_order_func=lambda x: x.metadata.get("order", 100),
                get_role_func=lambda x: x.role.value,
                get_internal_order_func=lambda x: x.metadata.get("original_order", 0)
            )
            
            # æŒ‰æ’åºåçš„é¡ºåºæ’å…¥é¢„è®¾
            for preset_msg in sorted_presets:
                depth = preset_msg.metadata.get("depth", 0)
                if depth and len(merged_history) >= depth:
                    insert_pos = len(merged_history) - depth
                    merged_history.insert(insert_pos, preset_msg)
                else:
                    merged_history.append(preset_msg)
        else:
            # å¦‚æœæ²¡æœ‰in-chaté¢„è®¾ï¼Œä¿æŒåŸé€»è¾‘
            sorted_presets = []
        
        full_history.extend(merged_history)
        
        return full_history
    
    def _process_macros(self, content: str) -> str:
        """å¤„ç†å†…å®¹ä¸­çš„å®ï¼Œæ”¯æŒåµŒå¥—å®"""
        try:
            # è·å–æˆ–åˆ›å»ºå®å¤„ç†å™¨å®ä¾‹
            if self._macro_processor is None:
                macro_context = self._build_macro_context()
                self._macro_processor = MacroProcessor(macro_context)
            else:
                # æ›´æ–°ä¸Šä¸‹æ–‡ï¼ˆç”¨æˆ·æ¶ˆæ¯å¯èƒ½å·²ç»æ”¹å˜ï¼‰
                macro_context = self._build_macro_context()
                self._macro_processor.context = macro_context
            
            # å¤šæ¬¡å¤„ç†ä»¥æ”¯æŒåµŒå¥—å®ï¼Œæœ€å¤š5æ¬¡é˜²æ­¢æ— é™å¾ªç¯
            result = content
            max_iterations = 5
            
            for i in range(max_iterations):
                prev_result = result
                result = self._macro_processor._process_string(result)
                
                # å¦‚æœæ²¡æœ‰å˜åŒ–ï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šå®éœ€è¦å¤„ç†
                if result == prev_result:
                    break
            
            return result
            
        except Exception as e:
            # å¦‚æœå®å¤„ç†å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›åŸå§‹å†…å®¹
            print(f"âš ï¸ å®å¤„ç†å¤±è´¥: {e}")
            return content
    
    def _process_messages_with_macros(self, messages: List[ChatMessage]) -> List[Dict[str, str]]:
        """æŒ‰é¡ºåºå¤„ç†æ¶ˆæ¯åˆ—è¡¨ä¸­çš„å®ï¼Œä¿æŒå˜é‡çŠ¶æ€"""
        # é‡ç½®å®å¤„ç†å™¨ä»¥æ¸…ç©ºå˜é‡çŠ¶æ€
        self._macro_processor = None
        
        processed_messages = []
        
        for msg in messages:
            content = msg.content
            
            # å¤„ç†å½“å‰æ¶ˆæ¯ä¸­çš„å®
            if content.strip():  # åªå¤„ç†éç©ºå†…å®¹
                processed_content = self._process_macros(content)
                
                # å¢å¼ºçš„å®åæ¢è¡Œç¬¦æ¸…ç†
                cleaned_content = self._aggressive_clean_macro_artifacts(processed_content)
                
                # æœ€ç»ˆæ£€æŸ¥ï¼Œç¡®ä¿æ¸…ç†åä»æœ‰å†…å®¹
                if cleaned_content.strip():
                    processed_messages.append({
                        "role": msg.role.value,
                        "content": cleaned_content
                    })
                # å¦‚æœå®æ‰§è¡Œåå†…å®¹ä¸ºç©ºï¼Œç›´æ¥è·³è¿‡è¿™ä¸ªæ¶ˆæ¯
            # å¦‚æœåŸå§‹å†…å®¹ä¸ºç©ºï¼Œä¹Ÿè·³è¿‡
        
        return processed_messages
    
    def _aggressive_clean_macro_artifacts(self, content: str) -> str:
        """å¢å¼ºçš„å®åæ¸…ç†ï¼Œå½»åº•ç§»é™¤å®è°ƒç”¨ç•™ä¸‹çš„ç©ºç™½å ä½"""
        import re
        
        if not content:
            return ""
        
        # 1. é¦–å…ˆè¿›è¡ŒåŸºç¡€æ¸…ç†
        cleaned = content.strip()
        if not cleaned:
            return ""
        
        # 2. å°†å†…å®¹æŒ‰è¡Œåˆ†å‰²
        lines = cleaned.split('\n')
        
        # 3. æ›´æ™ºèƒ½çš„è¡Œçº§æ¸…ç†
        cleaned_lines = []
        for line in lines:
            # ç§»é™¤åªåŒ…å«ç©ºç™½å­—ç¬¦çš„è¡Œï¼ˆç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ç­‰ï¼‰
            if line.strip():
                cleaned_lines.append(line)
            # å®Œå…¨ç©ºçš„è¡Œä¼šè¢«è·³è¿‡ï¼Œé™¤éå®ƒåœ¨æœ‰å†…å®¹çš„è¡Œä¹‹é—´ï¼ˆä½œä¸ºæ®µè½åˆ†éš”ï¼‰
        
        # 4. é‡æ–°ç»„åˆå¹¶è¿›è¡Œæ®µè½çº§æ¸…ç†
        if not cleaned_lines:
            return ""
        
        # 5. å¤„ç†æ®µè½é—´çš„ç©ºè¡Œï¼šä¿ç•™å¿…è¦çš„åˆ†æ®µï¼Œä½†ä¸å…è®¸è¶…è¿‡1ä¸ªç©ºè¡Œ
        result_content = '\n'.join(cleaned_lines)
        
        # 6. è¿›è¡Œæœ€ç»ˆçš„æ¢è¡Œç¬¦ä¼˜åŒ–
        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„æ¢è¡Œç¬¦
        result_content = result_content.strip()
        
        # å°†è¿ç»­çš„å¤šä¸ªæ¢è¡Œç¬¦å‹ç¼©ä¸ºæœ€å¤š2ä¸ªï¼ˆä¿æŒæ®µè½åˆ†éš”ï¼‰
        result_content = re.sub(r'\n{3,}', '\n\n', result_content)
        
        # 7. å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šå®æ›¿æ¢åå¯èƒ½ç•™ä¸‹çš„å­¤ç«‹æ ‡ç‚¹ç¬¦å·è¡Œ
        lines = result_content.split('\n')
        final_lines = []
        
        for line in lines:
            stripped_line = line.strip()
            # è·³è¿‡åªåŒ…å«å¸¸è§å®æ®‹ç•™ç¬¦å·çš„è¡Œ
            if stripped_line and not re.match(r'^[,\.\-_\s]*$', stripped_line):
                final_lines.append(line)
            elif not stripped_line and final_lines and not final_lines[-1].strip():
                # è·³è¿‡è¿ç»­çš„ç©ºè¡Œ
                continue
            elif stripped_line:  # ä¿ç•™æœ‰å®é™…å†…å®¹çš„è¡Œ
                final_lines.append(line)
        
        # 8. æœ€ç»ˆæ¸…ç†å’ŒéªŒè¯
        final_content = '\n'.join(final_lines).strip()
        
        # 9. æœ€åä¸€æ¬¡æ¢è¡Œç¬¦å‹ç¼©
        final_content = re.sub(r'\n{3,}', '\n\n', final_content)
        
        return final_content
    
    def _build_macro_context(self) -> Dict[str, Any]:
        """æ„å»ºå®å¤„ç†æ‰€éœ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = {}
        
        # ç”¨æˆ·åå’Œè§’è‰²å
        if hasattr(self, 'persona_data') and self.persona_data:
            context["user"] = self.persona_data.get("name", "User")
        else:
            context["user"] = "User"
        
        if self.character_data:
            context["char"] = self.character_data.get("name", "Assistant")
            context["description"] = self.character_data.get("description", "")
            context["personality"] = self.character_data.get("personality", "")
            context["scenario"] = self.character_data.get("scenario", "")
        else:
            context["char"] = "Assistant"
            context["description"] = ""
            context["personality"] = ""
            context["scenario"] = ""
        
        # æœ€åçš„ç”¨æˆ·æ¶ˆæ¯
        last_user_message = ""
        last_char_message = ""
        last_message = ""
        
        for msg in reversed(self.chat_history):
            if msg.role == MessageRole.USER and not last_user_message:
                last_user_message = msg.content
            elif msg.role == MessageRole.ASSISTANT and not last_char_message:
                last_char_message = msg.content
            
            if not last_message:
                last_message = msg.content
                
            # å¦‚æœéƒ½æ‰¾åˆ°äº†å°±åœæ­¢
            if last_user_message and last_char_message and last_message:
                break
        
        context["lastUserMessage"] = last_user_message
        context["lastCharMessage"] = last_char_message
        context["lastMessage"] = last_message
        
        # èŠå¤©ç»Ÿè®¡
        user_count = len([msg for msg in self.chat_history if msg.role == MessageRole.USER])
        total_count = len(self.chat_history)
        total_chars = sum(len(msg.content) for msg in self.chat_history)
        
        context["messageCount"] = str(total_count)
        context["userMessageCount"] = str(user_count)
        context["conversationLength"] = str(total_chars)
        
        return context
    
    def to_openai_messages(self, enable_macros: Optional[bool] = None) -> List[Dict[str, str]]:
        """è½¬æ¢ä¸ºOpenAI APIæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨"""
        # ç¡®å®šæ˜¯å¦å¯ç”¨å®å¤„ç†
        use_macros = enable_macros if enable_macros is not None else self.enable_macros
        
        full_history = self.get_full_chat_history()
        
        if use_macros:
            # æŒ‰é¡ºåºå¤„ç†æ‰€æœ‰æ¶ˆæ¯ä¸­çš„å®
            return self._process_messages_with_macros(full_history)
        else:
            # ä¸å¤„ç†å®ï¼Œç›´æ¥è½¬æ¢
            return [
                {
                    "role": msg.role.value,
                    "content": msg.content
                }
                for msg in full_history
            ]
    
    def to_final_prompt_openai(self, enable_macros: Optional[bool] = None) -> List[Dict[str, str]]:
        """è½¬æ¢æœ€ç»ˆæç¤ºè¯ä¸ºOpenAI APIæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨"""
        # æ¸…ç©ºenabledç¼“å­˜ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çŠ¶æ€
        self.clear_enabled_cache()
        
        # ç¡®å®šæ˜¯å¦å¯ç”¨å®å¤„ç†
        use_macros = enable_macros if enable_macros is not None else self.enable_macros
        
        final_prompt = self.build_final_prompt()
        
        if use_macros:
            # æŒ‰é¡ºåºå¤„ç†æ‰€æœ‰æ¶ˆæ¯ä¸­çš„å®ï¼ˆç°åœ¨å·²ç»åŒ…å«ç©ºå†…å®¹è¿‡æ»¤ï¼‰
            return self._process_messages_with_macros(final_prompt)
        else:
            # ä¸å¤„ç†å®ï¼Œç›´æ¥è½¬æ¢
            return [
                {
                    "role": msg.role.value,
                    "content": msg.content
                }
                for msg in final_prompt
            ]
    
    def clear_triggered_entries(self) -> None:
        """æ¸…ç©ºå·²è§¦å‘çš„ä¸–ç•Œä¹¦æ¡ç›®è®°å½•"""
        self.triggered_entries.clear()
    
    def clear_macro_variables(self) -> None:
        """æ¸…ç©ºå®å˜é‡çŠ¶æ€"""
        if self._macro_processor:
            self._macro_processor._variables.clear()
    
    def get_macro_variables(self) -> Dict[str, str]:
        """è·å–å½“å‰å®å˜é‡çŠ¶æ€"""
        if self._macro_processor:
            return self._macro_processor._variables.copy()
        return {}
    
    def reset_chat_history(self) -> None:
        """é‡ç½®èŠå¤©å†å²"""
        self.chat_history.clear()
        self.triggered_entries.clear()
        # é‡ç½®å®å¤„ç†å™¨ï¼Œæ¸…ç©ºå˜é‡çŠ¶æ€
        self._macro_processor = None
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        full_history = self.get_full_chat_history()
        
        role_counts = {}
        for msg in full_history:
            role = msg.role.value
            role_counts[role] = role_counts.get(role, 0) + 1
        
        return {
            "total_messages": len(full_history),
            "user_messages": len([msg for msg in self.chat_history if msg.role == MessageRole.USER]),
            "assistant_messages": len([msg for msg in self.chat_history if msg.role == MessageRole.ASSISTANT]),
            "role_distribution": role_counts,
            "triggered_world_book_entries": len(self.triggered_entries),
            "always_world_book_entries": len([e for e in self.world_book_entries if self._should_include_in_initial_build(e) and e.mode == "always"]),
            "in_chat_presets": len([p for p in self.preset_prompts if self._should_include_in_initial_build(p) and p.position == "in-chat"])
        }


    def _get_world_info_before_content(self) -> str:
        """è·å–world_info_beforeçš„å†…å®¹"""
        # ç­›é€‰ç¬¦åˆæ¡ä»¶çš„æ¡ç›®ï¼ˆåˆå§‹åŒ…å«éç¡®å®šç¦ç”¨çš„ï¼‰
        entries = [entry for entry in self.world_book_entries 
                  if self._should_include_in_initial_build(entry) and entry.position == "before_char"]
        
        # æŒ‰ç…§æ¬¡åºè§„åˆ™æ’åº
        if entries:
            # ä¸ºæ¯ä¸ªæ¡ç›®æ·»åŠ åŸå§‹é¡ºåºæ ‡è®°
            for i, entry in enumerate(entries):
                entry._original_order = i
            
            # æŒ‰æ¬¡åºè§„åˆ™æ’åºï¼ˆæ³¨æ„ï¼šæ•°å­—å°çš„orderè¦é å‰ï¼‰
            entries = self._sort_by_order_rules(
                entries,
                get_depth_func=lambda x: getattr(x, 'depth', None),
                get_order_func=lambda x: getattr(x, 'order', 100),
                get_role_func=lambda x: "system",  # before_charé»˜è®¤ä¸ºsystem role
                get_internal_order_func=lambda x: getattr(x, '_original_order', 0)
            )
        
        # æå–å†…å®¹å¹¶ç”¨1ä¸ªæ¢è¡Œç¬¦åˆ†éš”
        content_list = [entry.content for entry in entries if entry.content.strip()]
        return "\n".join(content_list)
    
    def _get_world_info_after_content(self) -> str:
        """è·å–world_info_afterçš„å†…å®¹"""
        # ç­›é€‰ç¬¦åˆæ¡ä»¶çš„æ¡ç›®ï¼ˆåˆå§‹åŒ…å«éç¡®å®šç¦ç”¨çš„ï¼‰
        entries = [entry for entry in self.world_book_entries 
                  if self._should_include_in_initial_build(entry) and entry.position == "after_char"]
        
        # æŒ‰ç…§æ¬¡åºè§„åˆ™æ’åº
        if entries:
            # ä¸ºæ¯ä¸ªæ¡ç›®æ·»åŠ åŸå§‹é¡ºåºæ ‡è®°
            for i, entry in enumerate(entries):
                entry._original_order = i
            
            # æŒ‰æ¬¡åºè§„åˆ™æ’åºï¼ˆæ³¨æ„ï¼šæ•°å­—å°çš„orderè¦é å‰ï¼‰
            entries = self._sort_by_order_rules(
                entries,
                get_depth_func=lambda x: getattr(x, 'depth', None),
                get_order_func=lambda x: getattr(x, 'order', 100),
                get_role_func=lambda x: "system",  # after_charé»˜è®¤ä¸ºsystem role
                get_internal_order_func=lambda x: getattr(x, '_original_order', 0)
            )
        
        # æå–å†…å®¹å¹¶ç”¨1ä¸ªæ¢è¡Œç¬¦åˆ†éš”
        content_list = [entry.content for entry in entries if entry.content.strip()]
        return "\n".join(content_list)
    
    def _resolve_special_identifier_content(self, identifier: str) -> str:
        """è§£æç‰¹æ®Šidentifierçš„å†…å®¹"""
        if identifier == "chatHistory":
            # è¿”å›chatHistoryçš„æ¶ˆæ¯ç»„åˆï¼Œä½¿ç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†éš”
            messages = self.get_full_chat_history()
            content_parts = []
            for msg in messages:
                content_parts.append(f"[{msg.role.value}] {msg.content}")
            return "\n\n".join(content_parts)
        
        elif identifier == "worldInfoBefore":
            return self._get_world_info_before_content()
        
        elif identifier == "worldInfoAfter":
            return self._get_world_info_after_content()
        
        elif identifier == "charDescription":
            return self.character_data.get("description", "")
        
        elif identifier == "personaDescription":
            # ä»åŠ è½½çš„ç©å®¶å¡æ•°æ®ä¸­è·å–æè¿°ï¼Œåªè¿”å›descriptionå†…å®¹
            if hasattr(self, 'persona_data') and self.persona_data:
                return self.persona_data.get("description", "")
            return ""
        
        elif identifier in ["charPersonality", "scenario", "dialogueExamples"]:
            # è¿™äº›æ ‡è¯†ç¬¦ä½¿ç”¨ç©ºå†…å®¹
            return ""
        
        else:
            # å…¶ä»–æ ‡è¯†ç¬¦è¿”å›Noneï¼Œè¡¨ç¤ºä½¿ç”¨åŸå§‹content
            return None
    
    def get_relative_preset_blocks(self) -> List[ChatMessage]:
        """è·å–relativeä½ç½®çš„é¢„è®¾å—"""
        blocks = []
        
        # æŒ‰ç…§é¢„è®¾çš„é¡ºåºå¤„ç†relativeä½ç½®çš„é¢„è®¾
        for prompt in self.preset_prompts:
            if self._should_include_in_initial_build(prompt) and prompt.position == "relative":
                # è§£æç‰¹æ®Šidentifier
                special_content = self._resolve_special_identifier_content(prompt.identifier)
                
                if special_content is not None:
                    # ä½¿ç”¨ç‰¹æ®Šcontent
                    content = special_content
                else:
                    # ä½¿ç”¨åŸå§‹content
                    content = prompt.content or ""
                
                # è·³è¿‡å®Œå…¨ç©ºçš„å†…å®¹ï¼ˆåŒ…æ‹¬åªæœ‰ç©ºç™½å­—ç¬¦çš„å†…å®¹ï¼‰
                # ä½†æ˜¯å¯¹äºç‰¹æ®Šæ ‡è¯†ç¬¦ï¼Œå³ä½¿å†…å®¹ä¸ºç©ºä¹Ÿè¦ä¿ç•™å ä½
                if not content.strip() and prompt.identifier not in ["charPersonality", "scenario", "dialogueExamples", "personaDescription", "charDescription"]:
                    continue
                
                role = MessageRole(prompt.role) if prompt.role in ["system", "user", "assistant"] else MessageRole.SYSTEM
                
                block = ChatMessage(
                    role=role,
                    content=content,
                    metadata={
                        "source": "relative_preset",
                        "identifier": prompt.identifier,
                        "name": prompt.name
                    }
                )
                blocks.append(block)
        
        return blocks
    
    def _merge_adjacent_roles(self, messages: List[ChatMessage]) -> List[ChatMessage]:
        """åˆå¹¶ç›¸é‚»çš„ç›¸åŒroleå—ï¼Œä¿ç•™æ‰€æœ‰æ¥æºä¿¡æ¯ï¼Œæ”¯æŒå¤šå†…å®¹éƒ¨åˆ†"""
        if not messages:
            return []
        
        merged = []
        current_role = None
        current_content_parts = []  # å­˜å‚¨ContentPartå¯¹è±¡
        current_metadata = {}
        
        for msg in messages:
            if msg.role == current_role:
                # ç›¸åŒroleï¼Œåˆå¹¶å†…å®¹éƒ¨åˆ†
                if msg.content_parts:
                    # æ·»åŠ æ‰€æœ‰å†…å®¹éƒ¨åˆ†ï¼ˆåŒ…æ‹¬ç©ºå†…å®¹ï¼Œç”¨äºä¿æŒç»“æ„ï¼‰
                    for part in msg.content_parts:
                        current_content_parts.append(part)
                else:
                    # å‘åå…¼å®¹ï¼šå¤„ç†æ—§æ ¼å¼çš„content
                    merged_content = msg.get_merged_content()
                    # ä¿ç•™æ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬ç©ºå†…å®¹ï¼ˆç”¨äºç‰¹æ®Šæ ‡è¯†ç¬¦ï¼‰
                    content_part = ContentPart(
                        content=merged_content,
                        source_type=msg.get_primary_source_type(),
                        source_id=msg.metadata.get("identifier", "unknown")
                    )
                    current_content_parts.append(content_part)
                
                # åˆå¹¶metadata
                if "identifiers" not in current_metadata:
                    current_metadata["identifiers"] = []
                current_metadata["identifiers"].append(msg.metadata.get("identifier", ""))
                
            else:
                # ä¸åŒroleï¼Œä¿å­˜ä¹‹å‰çš„å¹¶å¼€å§‹æ–°çš„
                if current_role is not None:
                    # åˆ›å»ºèåˆåçš„æ¶ˆæ¯
                    merged_msg = ChatMessage(
                        role=current_role,
                        content_parts=current_content_parts.copy(),
                        metadata=current_metadata
                    )
                    merged.append(merged_msg)
                
                # å¼€å§‹æ–°çš„roleå—
                current_role = msg.role
                current_metadata = {
                    "source": "merged_preset",
                    "identifiers": [msg.metadata.get("identifier", "")]
                }
                
                # åˆå§‹åŒ–å†…å®¹éƒ¨åˆ†ï¼ˆåªæ·»åŠ éç©ºå†…å®¹ï¼‰
                current_content_parts = []
                if msg.content_parts:
                    for part in msg.content_parts:
                        if part.content.strip():
                            current_content_parts.append(part)
                else:
                    # å‘åå…¼å®¹
                    merged_content = msg.get_merged_content()
                    if merged_content.strip():
                        content_part = ContentPart(
                            content=merged_content,
                            source_type=msg.get_primary_source_type(),
                            source_id=msg.metadata.get("identifier", "unknown")
                        )
                        current_content_parts = [content_part]
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_role is not None:
            merged_msg = ChatMessage(
                role=current_role,
                content_parts=current_content_parts.copy(),
                metadata=current_metadata
            )
            merged.append(merged_msg)
        
        # æ™ºèƒ½è¿‡æ»¤ï¼šä¿ç•™æœ‰å®é™…å†…å®¹æˆ–æœ‰é‡è¦æ ‡è¯†ç¬¦çš„æ¶ˆæ¯å—
        filtered_merged = []
        for msg in merged:
            merged_content = msg.get_merged_content()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡è¦çš„æ ‡è¯†ç¬¦
            identifiers = msg.metadata.get("identifiers", [])
            important_identifiers = ["charDescription", "personaDescription", "worldInfoBefore", "worldInfoAfter", "chatHistory"]
            has_important_identifier = any(id in important_identifiers for id in identifiers if id)
            
            # ä¿ç•™æœ‰å†…å®¹æˆ–æœ‰é‡è¦æ ‡è¯†ç¬¦çš„æ¶ˆæ¯
            if merged_content.strip() or has_important_identifier or identifiers:
                filtered_merged.append(msg)
        
        return filtered_merged
    
    def build_final_prompt(self) -> List[ChatMessage]:
        """æ„å»ºæœ€ç»ˆçš„æç¤ºè¯ï¼ˆåŠ¨æ€æ‰§è¡Œæ¨¡å¼ï¼‰"""
        return self.build_final_prompt_dynamic()
    
    def build_final_prompt_dynamic(self) -> List[ChatMessage]:
        """åŠ¨æ€æ„å»ºæœ€ç»ˆæç¤ºè¯ï¼šå…ˆåŒ…å«éç¡®å®šç¦ç”¨çš„ï¼Œå†ä»ä¸Šåˆ°ä¸‹æ‰§è¡Œåˆ¤æ–­"""
        print("ğŸ”„ å¼€å§‹åŠ¨æ€æ„å»ºæç¤ºè¯")
        
        # 1. æ¸…ç©ºenabledç¼“å­˜ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çŠ¶æ€
        self.clear_enabled_cache()
        
        # 2. å…ˆæ„å»ºåŒ…å«æ‰€æœ‰"éç¡®å®šç¦ç”¨"æ¡ç›®çš„åˆå§‹æç¤ºè¯
        print("ğŸ“‹ æ„å»ºåˆå§‹æç¤ºè¯ï¼ˆåŒ…å«æ‰€æœ‰éç¡®å®šç¦ç”¨çš„æ¡ç›®ï¼‰")
        initial_blocks = self.get_relative_preset_blocks()
        
        # 3. ä»ä¸Šåˆ°ä¸‹æ‰§è¡Œï¼ŒåŠ¨æ€åˆ¤æ–­æ¯ä¸ªæ¡ç›®çš„enabledçŠ¶æ€
        print("ğŸ”„ å¼€å§‹ä»ä¸Šåˆ°ä¸‹åŠ¨æ€æ‰§è¡Œåˆ¤æ–­")
        filtered_blocks = []
        
        for i, block in enumerate(initial_blocks):
            # è·å–æºæ¡ç›®ä¿¡æ¯
            source_type = block.metadata.get("source", "unknown")
            identifier = block.metadata.get("identifier", "")
            name = block.metadata.get("name", "")
            
            # æ ¹æ®æºç±»å‹æ‰¾åˆ°å¯¹åº”çš„æ¡ç›®è¿›è¡Œenabledåˆ¤æ–­
            should_include = True
            
            if source_type == "relative_preset":
                # æŸ¥æ‰¾å¯¹åº”çš„é¢„è®¾æ¡ç›®
                preset = None
                for p in self.preset_prompts:
                    if p.identifier == identifier:
                        preset = p
                        break
                
                if preset:
                    # åŠ¨æ€åˆ¤æ–­enabledçŠ¶æ€
                    should_include = self._evaluate_enabled(preset)
                    if should_include and preset.code_block and preset.code_block.strip():
                        # çœŸæ­£æ‰§è¡Œé¢„è®¾çš„ä»£ç å—ï¼Œå½±å“å®å¤„ç†å™¨çŠ¶æ€
                        print(f"ğŸ“‹ æ‰§è¡Œé¢„è®¾ä»£ç å—: {preset.name}")
                        try:
                            # ç¡®ä¿æœ‰å®å¤„ç†å™¨
                            if not hasattr(self, '_macro_processor') or self._macro_processor is None:
                                macro_context = self._build_macro_context()
                                from macro_processor import MacroProcessor
                                self._macro_processor = MacroProcessor(macro_context)
                            
                            # ä½¿ç”¨å®å¤„ç†å™¨æ‰§è¡ŒåŒ…å«Pythonä»£ç çš„å­—ç¬¦ä¸²
                            wrapped_code = f"{{{{python:{preset.code_block}}}}}"
                            result = self._macro_processor._process_string(wrapped_code)
                            print(f"âœ… é¢„è®¾ä»£ç å—æ‰§è¡ŒæˆåŠŸ: {preset.name}")
                            
                            # æ¸…ç©ºenabledç¼“å­˜ï¼Œè®©åç»­åˆ¤æ–­ä½¿ç”¨æ–°çŠ¶æ€
                            self.clear_enabled_cache()
                            
                        except Exception as e:
                            print(f"âŒ é¢„è®¾ä»£ç å—æ‰§è¡Œå¤±è´¥ ({preset.name}): {e}")
            
            # æ ¹æ®åˆ¤æ–­ç»“æœå†³å®šæ˜¯å¦åŒ…å«
            if should_include:
                filtered_blocks.append(block)
                print(f"âœ… åŒ…å«æ¡ç›®: {name or identifier} ({source_type})")
            else:
                print(f"â­ï¸  è·³è¿‡ç¦ç”¨æ¡ç›®: {name or identifier} ({source_type})")
        
        # 4. åˆå¹¶ç›¸é‚»çš„ç›¸åŒroleå—
        final_prompt = self._merge_adjacent_roles(filtered_blocks)
        
        print(f"ğŸ‰ åŠ¨æ€æ„å»ºå®Œæˆï¼Œæœ€ç»ˆåŒ…å« {len(final_prompt)} ä¸ªæ¶ˆæ¯å—")
        return final_prompt
    
    def to_final_prompt_openai(self, execute_code: bool = True) -> List[Dict[str, str]]:
        """è½¬æ¢æœ€ç»ˆæç¤ºè¯ä¸ºOpenAI APIæ ¼å¼ï¼Œå¹¶å¯é€‰æ‰§è¡Œä»£ç å—"""
        # 0. æ¸…ç©ºenabledç¼“å­˜ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çŠ¶æ€
        self.clear_enabled_cache()
        
        # 1. ä½¿ç”¨æ–°çš„ç»Ÿä¸€æ‰§è¡Œæ–¹æ³•ï¼ˆå¦‚æœå¯ç”¨ä»£ç æ‰§è¡Œï¼‰
        if execute_code:
            openai_messages = self._execute_unified_sequential()
        else:
            # ä¸æ‰§è¡Œä»£ç æ—¶ï¼Œä½¿ç”¨åŸæœ‰çš„æ„å»ºæ–¹å¼
            final_prompt = self.build_final_prompt()
            openai_messages = [msg.to_openai_format() for msg in final_prompt]
        
        return openai_messages
    
    def to_raw_openai_format(self) -> List[Dict[str, Any]]:
        """
        è¾“å‡ºæ ¼å¼1: æœ€åˆæœªç»è¿‡enabledåˆ¤æ–­çš„åŸå§‹æç¤ºè¯
        åŒ…å«æ‰€æœ‰æ¡ç›®ï¼Œä¸è¿›è¡Œenabledè¿‡æ»¤ï¼Œä¸æ‰§è¡Œä»£ç å—
        """
        # æ„å»ºåŒ…å«æ‰€æœ‰æ¡ç›®çš„åŸå§‹æç¤ºè¯ï¼Œå¿½ç•¥enabledçŠ¶æ€
        original_enable_macros = self.enable_macros
        self.enable_macros = False  # ä¸´æ—¶ç¦ç”¨å®å¤„ç†
        
        try:
            # æ”¶é›†æ‰€æœ‰æ¶ˆæ¯æ¥æºï¼Œä¸è¿›è¡Œenabledè¿‡æ»¤
            all_sources = []
            
            # æ·»åŠ ä¸–ç•Œä¹¦æ¡ç›®ï¼ˆæ‰€æœ‰æ¡ç›®ï¼Œä¸ç®¡enabledçŠ¶æ€ï¼‰
            for entry in self.world_book_entries:
                all_sources.append({
                    'type': 'world_book',
                    'name': entry.name,
                    'content': entry.content,
                    'role': 'system',
                    'injection_order': getattr(entry, 'injection_order', 0),
                    'enabled': True  # å¼ºåˆ¶å¯ç”¨æ‰€æœ‰æ¡ç›®
                })
            
            # æ·»åŠ é¢„è®¾ï¼ˆæ‰€æœ‰é¢„è®¾ï¼Œä¸ç®¡enabledçŠ¶æ€ï¼‰
            for preset in self.preset_prompts:
                all_sources.append({
                    'type': 'preset',
                    'name': preset.name,
                    'content': preset.content,
                    'role': preset.role.value if hasattr(preset.role, 'value') else str(preset.role),
                    'injection_order': getattr(preset, 'injection_order', 0),
                    'enabled': True  # å¼ºåˆ¶å¯ç”¨æ‰€æœ‰é¢„è®¾
                })
            
            # æ·»åŠ èŠå¤©å†å²
            for i, msg in enumerate(self.chat_history):
                all_sources.append({
                    'type': 'chat_history',
                    'name': f'chat_message_{i}',
                    'content': msg.get_merged_content(),
                    'role': msg.role.value if hasattr(msg.role, 'value') else str(msg.role),
                    'injection_order': getattr(msg, 'injection_order', 1000 + i),
                    'enabled': True
                })
            
            # æŒ‰injection_orderæ’åº
            all_sources.sort(key=lambda x: x.get('injection_order', 0))
            
            # è½¬æ¢ä¸ºOpenAIæ ¼å¼
            openai_messages = []
            for source in all_sources:
                message = {
                    "role": source['role'],
                    "content": source['content'],
                    "_content_parts": [{
                        "content": source['content'],
                        "source_type": source['type'],
                        "source_id": source['name'],
                        "source_label": source['name']
                    }],
                    "_source_types": [source['type']]
                }
                openai_messages.append(message)
            
            return openai_messages
            
        finally:
            self.enable_macros = original_enable_macros  # æ¢å¤åŸå§‹è®¾ç½®
    
    def to_processed_openai_format(self, execute_code: bool = True) -> List[Dict[str, Any]]:
        """
        è¾“å‡ºæ ¼å¼2: ç»è¿‡enabledåˆ¤æ–­å’Œå¤„ç†çš„æç¤ºè¯
        å·²å¤„ç†contentã€code blockã€å®ç­‰ï¼Œä½†ä¿ç•™æ¥æºä¿¡æ¯
        è¿™æ˜¯å½“å‰to_final_prompt_openaiæ–¹æ³•çš„åŠŸèƒ½
        """
        return self.to_final_prompt_openai(execute_code=execute_code)
    
    def to_clean_openai_format(self, execute_code: bool = True) -> List[Dict[str, str]]:
        """
        è¾“å‡ºæ ¼å¼3: å»æ‰æ¥æºä¿¡æ¯çš„æ ‡å‡†OpenAIæ ¼å¼
        å®Œå…¨ç¬¦åˆOpenAI APIè§„èŒƒï¼ŒåªåŒ…å«roleå’Œcontentå­—æ®µ
        """
        # è·å–å·²å¤„ç†çš„æ¶ˆæ¯
        processed_messages = self.to_processed_openai_format(execute_code=execute_code)
        
        # æ¸…ç†æ‰©å±•å­—æ®µï¼Œåªä¿ç•™æ ‡å‡†OpenAIå­—æ®µ
        clean_messages = []
        for msg in processed_messages:
            clean_msg = {
                "role": msg["role"],
                "content": msg["content"]
            }
            clean_messages.append(clean_msg)
        
        return clean_messages
    
    def _execute_unified_sequential(self) -> List[Dict[str, str]]:
        """ç»Ÿä¸€çš„ä»ä¸Šåˆ°ä¸‹æ‰§è¡Œæ–¹æ³•ï¼šenabledè¯„ä¼° â†’ code_blockæ‰§è¡Œ â†’ contentå¤„ç†"""
        if not self.enable_macros:
            # å¦‚æœç¦ç”¨å®ï¼Œä½¿ç”¨åŸæœ‰æ„å»ºæ–¹å¼
            final_prompt = self.build_final_prompt()
            return [msg.to_openai_format() for msg in final_prompt]
        
        print("ğŸš€ å¼€å§‹ç»Ÿä¸€çš„ä»ä¸Šåˆ°ä¸‹æ‰§è¡Œæµç¨‹")
        
        # 1. åˆå§‹åŒ–Pythonæ²™ç›’
        sandbox = self._init_python_sandbox()
        
        # 2. æ¸…ç©ºenabledç¼“å­˜
        self.clear_enabled_cache()
        
        # 3. è·å–æ‰€æœ‰æ½œåœ¨çš„æ¶ˆæ¯æ¥æºï¼ˆæŒ‰injection_orderæ’åºï¼‰
        all_sources = self._collect_all_message_sources()
        
        # 4. æŒ‰é¡ºåºé€æ¡ç›®å®Œæ•´å¤„ç†ï¼šenabledè¯„ä¼° â†’ code_blockæ‰§è¡Œ â†’ contentå¤„ç†
        processed_messages = []
        
        for source in all_sources:
            try:
                print(f"ğŸ“‹ å¤„ç†æ¡ç›®: {source.get('name', 'Unknown')} ({source.get('type', 'Unknown')})")
                
                # 4.1 åŠ¨æ€è¯„ä¼°enabledçŠ¶æ€ï¼ˆä½¿ç”¨å½“å‰æœ€æ–°çš„å˜é‡çŠ¶æ€ï¼‰
                if not self._evaluate_source_enabled(source, sandbox):
                    print(f"â­ï¸  è·³è¿‡ç¦ç”¨çš„æ¡ç›®: {source.get('name', 'Unknown')}")
                    continue
                
                # 4.2 æ‰§è¡Œcode_blockï¼ˆå¦‚æœæœ‰ï¼‰
                self._execute_source_code_block(source, sandbox)
                
                # 4.3 å¤„ç†contentå¹¶ç”Ÿæˆæ¶ˆæ¯
                messages = self._process_source_content(source, sandbox)
                processed_messages.extend(messages)
                
                # 4.4 æ¸…ç©ºenabledç¼“å­˜ï¼ˆè®©åç»­åˆ¤æ–­ä½¿ç”¨æ–°çŠ¶æ€ï¼‰
                self.clear_enabled_cache()
                
                print(f"âœ… æ¡ç›®å¤„ç†å®Œæˆ: {source.get('name', 'Unknown')}")
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ¡ç›®å¤±è´¥: {source.get('name', 'Unknown')} - {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # 5. åˆå¹¶ç›¸é‚»çš„ç›¸åŒroleæ¶ˆæ¯
        final_messages = self._merge_adjacent_openai_messages(processed_messages)
        
        print(f"ğŸ‰ ç»Ÿä¸€æ‰§è¡Œå®Œæˆï¼Œæœ€ç»ˆåŒ…å« {len(final_messages)} ä¸ªæ¶ˆæ¯")
        return final_messages
    
    def _execute_code_blocks_sequential(self, openai_messages: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """æŒ‰ä»ä¸Šåˆ°ä¸‹é¡ºåºæ‰§è¡Œä»£ç å—ï¼Œå¤„ç†å®å’ŒPythonæ²™ç›’"""
        if not self.enable_macros:
            return openai_messages
        
        # åˆ›å»ºPythonæ²™ç›’ï¼ˆå¦‚æœéœ€è¦ï¼‰
        sandbox = None
        try:
            # å°è¯•å¯¼å…¥Pythonæ²™ç›’
            sys.path.insert(0, str(Path(__file__).parent.parent / "utils"))
            from python_sandbox import PythonSandbox
            sandbox = PythonSandbox()
            
            # åˆå§‹åŒ–å¯¹è¯ä½œç”¨åŸŸ
            # è½¬æ¢èŠå¤©å†å²ä¸ºå­—å…¸æ ¼å¼
            chat_history_dicts = []
            for msg in self.chat_history:
                if hasattr(msg, 'role') and hasattr(msg, 'content'):
                    chat_history_dicts.append({
                        'role': msg.role.value if hasattr(msg.role, 'value') else str(msg.role),
                        'content': msg.content
                    })
                else:
                    chat_history_dicts.append({
                        'role': 'user',
                        'content': str(msg)
                    })
            
            sandbox.init_conversation_scope(
                chat_history=chat_history_dicts,
                context={
                    "character_data": self.character_data,
                    "persona_data": getattr(self, 'persona_data', {})
                }
            )
        except ImportError:
            print("âš ï¸ Pythonæ²™ç›’æœªæ‰¾åˆ°ï¼Œå°†åªå¤„ç†ä¼ ç»Ÿå®")
        
        # æŒ‰é¡ºåºå¤„ç†æ¯æ¡æ¶ˆæ¯
        processed_messages = []
        for msg in openai_messages:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šå†…å®¹éƒ¨åˆ†
            if "_content_parts" in msg and msg["_content_parts"]:
                # æ–°é€»è¾‘ï¼šåˆ†åˆ«å¤„ç†æ¯ä¸ªå†…å®¹éƒ¨åˆ†ï¼Œä½¿ç”¨å„è‡ªçš„ä½œç”¨åŸŸï¼Œä½†åœ¨æœ€åæ‰åˆå¹¶
                processed_parts = []
                
                for part in msg["_content_parts"]:
                    part_content = part["content"]
                    part_scope = part["source_type"]
                    
                    # 1. å¤„ç†ä¼ ç»Ÿå®
                    if self._macro_processor is None:
                        macro_context = {
                            "character_data": self.character_data,
                            "persona_data": getattr(self, 'persona_data', {}),
                            "chat_history": self.chat_history
                        }
                        self._macro_processor = MacroProcessor(macro_context)
                    part_content = self._macro_processor._process_string(part_content)
                    
                    # 2. å¤„ç†Pythonå®ï¼Œä½¿ç”¨è¯¥éƒ¨åˆ†çš„ä½œç”¨åŸŸ
                    part_content = self._process_python_macros(part_content, part_scope)
                    
                    # 3. æ‰§è¡ŒPythonä»£ç å—
                    if sandbox:
                        part_content = self._execute_python_blocks_in_content(part_content, sandbox)
                    
                    processed_parts.append(part_content)
                
                # æœ€ç»ˆæ‹¼æ¥ï¼šç”¨åŒæ¢è¡Œç¬¦åˆå¹¶å¤„ç†åçš„éƒ¨åˆ†
                processed_content = "\n\n".join(processed_parts)
            else:
                # å‘åå…¼å®¹ï¼šå•ä¸€å†…å®¹çš„æ¶ˆæ¯
                processed_content = msg["content"]
                
                # 1. é¦–å…ˆå¤„ç†ä¼ ç»Ÿå®
                if self._macro_processor is None:
                    macro_context = {
                        "character_data": self.character_data,
                        "persona_data": getattr(self, 'persona_data', {}),
                        "chat_history": self.chat_history
                    }
                    self._macro_processor = MacroProcessor(macro_context)
                processed_content = self._macro_processor._process_string(processed_content)
                
                # 1.5 å¤„ç†Pythonå®ï¼ˆä½¿ç”¨æ£€æµ‹åˆ°çš„ä½œç”¨åŸŸï¼‰
                scope_type = self._detect_content_scope(msg)
                processed_content = self._process_python_macros(processed_content, scope_type)
                
                # 2. ç„¶åæ‰§è¡ŒPythonä»£ç å—
                if sandbox:
                    processed_content = self._execute_python_blocks_in_content(processed_content, sandbox)
            
            # 3. å¯¹å¤„ç†åçš„å†…å®¹è¿›è¡Œå¢å¼ºæ¸…ç†
            final_content = self._aggressive_clean_macro_artifacts(processed_content)
            
            # 4. åªæœ‰æ¸…ç†åä»æœ‰å†…å®¹çš„æ¶ˆæ¯æ‰æ·»åŠ åˆ°ç»“æœä¸­
            if final_content.strip():
                processed_msg = {
                    "role": msg["role"],
                    "content": final_content
                }
                processed_messages.append(processed_msg)
        
        return processed_messages
    
    def _execute_python_blocks_in_content(self, content: str, sandbox) -> str:
        """åœ¨å†…å®¹ä¸­æŸ¥æ‰¾å¹¶æ‰§è¡ŒPythonä»£ç å—"""
        import re
        
        # æŸ¥æ‰¾ä»£ç å—æ¨¡å¼ï¼ˆç®€å•å®ç°ï¼Œåç»­å¯ä»¥æ‰©å±•ï¼‰
        code_block_pattern = r'```python\n(.*?)\n```'
        
        def execute_code_block(match):
            code = match.group(1)
            try:
                result = sandbox.execute_code(code, scope_type='temp')
                if result.success and result.result is not None:
                    return str(result.result)
                elif not result.success:
                    return f"[ä»£ç æ‰§è¡Œé”™è¯¯: {result.error}]"
                else:
                    return ""  # æˆåŠŸä½†æ— ç»“æœ
            except Exception as e:
                return f"[ä»£ç æ‰§è¡Œå¼‚å¸¸: {e}]"
        
        # æ›¿æ¢æ‰€æœ‰ä»£ç å—
        processed_content = re.sub(code_block_pattern, execute_code_block, content, flags=re.DOTALL)
        return processed_content
    
    def _detect_content_scope(self, msg: Dict[str, str]) -> str:
        """æ£€æµ‹æ¶ˆæ¯å†…å®¹çš„æ¥æºä½œç”¨åŸŸï¼ˆåŸºäºå¤šå†…å®¹éƒ¨åˆ†ç»“æ„ï¼‰"""
        # å¤„ç†æ–°çš„å¤šå†…å®¹éƒ¨åˆ†æ ¼å¼
        if "_content_parts" in msg and msg["_content_parts"]:
            content_parts = msg["_content_parts"]
            
            # ä½¿ç”¨ä¼˜å…ˆçº§ç­–ç•¥ç¡®å®šä¸»è¦ä½œç”¨åŸŸ
            # ä¼˜å…ˆçº§ï¼špreset > world > char > conversation > temp (æƒé™å±‚çº§)
            priority = {"preset": 4, "world": 3, "char": 2, "conversation": 1, "temp": 0}
            
            # å¦‚æœåŒ…å«ç³»ç»Ÿé¢„è®¾å†…å®¹ï¼Œä¼˜å…ˆä½¿ç”¨presetä½œç”¨åŸŸ
            for part in content_parts:
                if part["source_type"] == "preset":
                    return "preset"
            
            # å¦åˆ™ä½¿ç”¨ä¼˜å…ˆçº§æœ€é«˜çš„ä½œç”¨åŸŸ
            primary_type = max(
                (part["source_type"] for part in content_parts),
                key=lambda x: priority.get(x, 0)
            )
            return primary_type
        
        # å¤„ç†æ¥æºç±»å‹åˆ—è¡¨
        if "_source_types" in msg and msg["_source_types"]:
            source_types = msg["_source_types"]
            priority = {"preset": 4, "world": 3, "char": 2, "conversation": 1, "temp": 0}
            
            if "preset" in source_types:
                return "preset"
            
            return max(source_types, key=lambda x: priority.get(x, 0))
        
        # å›é€€åˆ°å†…å®¹åˆ†æï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
        content = msg.get('content', '')
        if 'worldInfoBefore' in content or 'worldInfoAfter' in content:
            return 'world'
        elif 'charDescription' in content:
            return 'char' 
        elif 'chatHistory' in content:
            return 'conversation'
        else:
            return 'preset'  # é»˜è®¤ä¸ºé¢„è®¾ä½œç”¨åŸŸ
    
    def _process_python_macros(self, content: str, scope_type: str = 'temp', sandbox=None) -> str:
        """å¤„ç†Pythonå®ï¼ˆæ”¯æŒä¼ å…¥å·²å­˜åœ¨çš„æ²™ç›’ï¼‰"""
        try:
            sys.path.insert(0, str(Path(__file__).parent.parent / "utils"))
            from python_macro_processor import create_python_macro_processor
            
            # åˆ›å»ºPythonå®å¤„ç†å™¨
            python_macro_processor = create_python_macro_processor(
                character_data=self.character_data,
                persona_data=getattr(self, 'persona_data', {}),
                chat_history=self.chat_history,
                shared_sandbox=sandbox  # ä¼ å…¥å…±äº«çš„æ²™ç›’
            )
            
            # å¤„ç†æ‰€æœ‰å®ï¼Œå¹¶ä¼ é€’ä½œç”¨åŸŸä¿¡æ¯
            return python_macro_processor.process_all_macros(content, scope_type)
            
        except ImportError:
            # å¦‚æœPythonå®å¤„ç†å™¨ä¸å¯ç”¨ï¼Œè¿”å›åŸå†…å®¹
            return content
        except Exception as e:
            print(f"âš ï¸ Pythonå®å¤„ç†å¤±è´¥: {e}")
            return content
    
    def _collect_code_blocks_from_sources(self) -> List[Dict[str, Any]]:
        """æ”¶é›†æ‰€æœ‰æ¥æºçš„ä»£ç å—ï¼ŒæŒ‰æœ€ç»ˆæç¤ºè¯é¡ºåºæ’åˆ—"""
        code_blocks = []
        
        # ä»è§’è‰²å¡æ”¶é›†ä»£ç å—
        if self.character_data and "code_block" in self.character_data:
            code_blocks.append({
                "source": "character",
                "code": self.character_data["code_block"],
                "scope": "char"
            })
        
        # ä»ä¸–ç•Œä¹¦æ¡ç›®æ”¶é›†ä»£ç å—ï¼ˆåˆå§‹åŒ…å«éç¡®å®šç¦ç”¨çš„ï¼‰
        for entry in self.world_book_entries:
            if (self._should_include_in_initial_build(entry) and 
                hasattr(entry, 'code_block') and 
                entry.code_block and 
                entry.code_block.strip()):
                code_blocks.append({
                    "source": f"world_book_{entry.id}",
                    "name": entry.name,
                    "code": entry.code_block,
                    "scope": "world",
                    "item": entry  # ä¿å­˜æ¡ç›®å¼•ç”¨ï¼Œç”¨äºåŠ¨æ€åˆ¤æ–­
                })
        
        # ä»é¢„è®¾æ”¶é›†ä»£ç å—ï¼ˆåˆå§‹åŒ…å«éç¡®å®šç¦ç”¨çš„ï¼‰
        for prompt in self.preset_prompts:
            if (self._should_include_in_initial_build(prompt) and 
                prompt.code_block and 
                prompt.code_block.strip()):
                code_blocks.append({
                    "source": f"preset_{prompt.identifier}",
                    "name": prompt.name,
                    "code": prompt.code_block,
                    "scope": "preset",
                    "item": prompt  # ä¿å­˜æ¡ç›®å¼•ç”¨ï¼Œç”¨äºåŠ¨æ€åˆ¤æ–­
                })
        
        return code_blocks
    
    def execute_all_code_blocks_sequential(self) -> Dict[str, Any]:
        """æŒ‰æœ€ç»ˆæç¤ºè¯é¡ºåºæ‰§è¡Œæ‰€æœ‰ä»£ç å—"""
        if not self.enable_macros:
            return {"success": False, "message": "å®å¤„ç†æœªå¯ç”¨"}
        
        try:
            # å¯¼å…¥Pythonæ²™ç®±ï¼ˆå¤„ç†å¯¼å…¥é—®é¢˜ï¼‰
            try:
                from python_sandbox import create_sandbox
                sandbox = create_sandbox()
            except ImportError:
                try:
                    from ..utils.python_sandbox import PythonSandbox
                    sandbox = PythonSandbox()
                except ImportError:
                    return {"success": False, "message": "Pythonæ²™ç›’æ¨¡å—æœªæ‰¾åˆ°"}
            
            # åˆå§‹åŒ–å¯¹è¯ä½œç”¨åŸŸï¼ˆå…¼å®¹ä¸åŒçš„APIï¼‰
            try:
                if hasattr(sandbox, 'scope_manager') and hasattr(sandbox.scope_manager, 'init_conversation_scope'):
                    sandbox.scope_manager.init_conversation_scope(
                        chat_history=self.chat_history,
                        context={
                            "character_data": self.character_data,
                            "persona_data": getattr(self, 'persona_data', {})
                        }
                    )
                else:
                    # å¦‚æœæ²¡æœ‰scope_managerï¼Œè·³è¿‡åˆå§‹åŒ–
                    print("âš ï¸  æ²™ç®±æ²¡æœ‰scope_managerï¼Œè·³è¿‡ä½œç”¨åŸŸåˆå§‹åŒ–")
            except Exception as e:
                print(f"âš ï¸  ä½œç”¨åŸŸåˆå§‹åŒ–å¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œ")
            
            # æ”¶é›†æ‰€æœ‰ä»£ç å—
            code_blocks = self._collect_code_blocks_from_sources()
            
            # æŒ‰é¡ºåºæ‰§è¡Œï¼ˆåŠ¨æ€åˆ¤æ–­enabledçŠ¶æ€ï¼‰
            execution_results = []
            executed_count = 0
            
            for block in code_blocks:
                # è·³è¿‡è§’è‰²ä»£ç å—ï¼ˆå·²åœ¨åˆå§‹åŒ–æ—¶æ‰§è¡Œï¼‰
                if block.get("scope") == "char":
                    continue
                
                # åŠ¨æ€åˆ¤æ–­æ˜¯å¦å¯ç”¨
                item = block.get("item")
                if item and not self._evaluate_enabled(item):
                    print(f"â­ï¸  è·³è¿‡ç¦ç”¨çš„ä»£ç å—: {block.get('name', 'Unknown')}")
                    execution_results.append({
                        "source": block["source"],
                        "success": True,
                        "result": "skipped_disabled",
                        "error": None,
                        "skipped": True
                    })
                    continue
                
                try:
                    print(f"ğŸ”„ æ‰§è¡Œä»£ç å—: {block.get('name', 'Unknown')} ({block['scope']})")
                    
                    # å…¼å®¹ä¸åŒçš„æ²™ç®±API
                    if hasattr(sandbox, 'execute_code'):
                        # æ–°çš„æ²™ç®±API
                        result = sandbox.execute_code(
                            block["code"], 
                            scope_type=block["scope"]
                        )
                        
                        success = result.success if hasattr(result, 'success') else bool(result)
                        error = result.error if hasattr(result, 'error') else None
                        result_value = result.result if hasattr(result, 'result') else result
                        
                    else:
                        # å›é€€åˆ°å®å¤„ç†å™¨æ‰§è¡Œ
                        if not hasattr(self, '_macro_processor') or self._macro_processor is None:
                            macro_context = self._build_macro_context()
                            from macro_processor import MacroProcessor
                            self._macro_processor = MacroProcessor(macro_context)
                        
                        wrapped_code = f"{{{{python:{block['code']}}}}}"
                        result_value = self._macro_processor._process_string(wrapped_code)
                        success = True
                        error = None
                    
                    if success:
                        executed_count += 1
                        print(f"âœ… ä»£ç å—æ‰§è¡ŒæˆåŠŸ")
                    else:
                        print(f"âŒ ä»£ç å—æ‰§è¡Œå¤±è´¥: {error}")
                    
                    execution_results.append({
                        "source": block["source"],
                        "success": success,
                        "result": result_value,
                        "error": error,
                        "skipped": False
                    })
                except Exception as e:
                    print(f"âŒ ä»£ç å—æ‰§è¡Œå¼‚å¸¸: {e}")
                    execution_results.append({
                        "source": block["source"],
                        "success": False,
                        "result": None,
                        "error": str(e),
                        "skipped": False
                    })
            
            total_blocks = len(code_blocks)
            skipped_count = len([r for r in execution_results if r.get("skipped", False)])
            
            # è·å–æœ€ç»ˆå˜é‡çŠ¶æ€ï¼ˆå…¼å®¹ä¸åŒAPIï¼‰
            final_variables = {}
            try:
                if hasattr(sandbox, 'scope_manager') and hasattr(sandbox.scope_manager, 'get_all_variables'):
                    final_variables = sandbox.scope_manager.get_all_variables()
                elif hasattr(self, '_macro_processor') and self._macro_processor:
                    final_variables = self._macro_processor._variables.copy()
                else:
                    final_variables = {"note": "å˜é‡çŠ¶æ€ä¸å¯ç”¨"}
            except Exception as e:
                final_variables = {"error": f"è·å–å˜é‡å¤±è´¥: {e}"}
                
            return {
                "success": True,
                "executed": executed_count,
                "skipped": skipped_count,
                "total": total_blocks,
                "execution_results": execution_results,
                "final_variables": final_variables
            }
            
        except ImportError:
            return {"success": False, "message": "Pythonæ²™ç›’æœªæ‰¾åˆ°"}
        except Exception as e:
            return {"success": False, "message": f"æ‰§è¡Œå¼‚å¸¸: {e}"}
    
    # =====================
    # æ–°çš„ç»Ÿä¸€æ‰§è¡Œè¾…åŠ©æ–¹æ³•
    # =====================
    
    def _init_python_sandbox(self):
        """åˆå§‹åŒ–Pythonæ²™ç›’"""
        sandbox = None
        try:
            # å°è¯•å¯¼å…¥Pythonæ²™ç›’
            sys.path.insert(0, str(Path(__file__).parent.parent / "utils"))
            from python_sandbox import PythonSandbox
            sandbox = PythonSandbox()
            
            # åˆå§‹åŒ–å¯¹è¯ä½œç”¨åŸŸ
            chat_history_dicts = []
            for msg in self.chat_history:
                if hasattr(msg, 'role') and hasattr(msg, 'content'):
                    chat_history_dicts.append({
                        'role': msg.role.value if hasattr(msg.role, 'value') else str(msg.role),
                        'content': msg.content
                    })
                else:
                    chat_history_dicts.append({
                        'role': 'user',
                        'content': str(msg)
                    })
            
            sandbox.init_conversation_scope(
                chat_history=chat_history_dicts,
                context={
                    "character_data": self.character_data,
                    "persona_data": getattr(self, 'persona_data', {})
                }
            )
            print("âœ… Pythonæ²™ç›’åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            print("âš ï¸ Pythonæ²™ç›’æœªæ‰¾åˆ°ï¼Œå°†åªå¤„ç†ä¼ ç»Ÿå®")
        except Exception as e:
            print(f"âš ï¸ Pythonæ²™ç›’åˆå§‹åŒ–å¤±è´¥: {e}")
        
        return sandbox
    
    def _collect_all_message_sources(self):
        """æ”¶é›†æ‰€æœ‰æ¶ˆæ¯æ¥æºï¼ˆé¢„è®¾ã€ä¸–ç•Œä¹¦ã€å¯¹è¯ï¼‰ï¼ŒæŒ‰injection_orderæ’åº"""
        all_sources = []
        
        # 1. æ”¶é›†é¢„è®¾æ¥æº
        for preset in self.preset_prompts:
            if self._should_include_in_initial_build(preset):
                all_sources.append({
                    'type': 'preset',
                    'data': preset,
                    'name': preset.name,
                    'order': preset.order or 100,
                    'role': preset.role,
                    'position': preset.position
                })
        
        # 2. æ”¶é›†ä¸–ç•Œä¹¦æ¥æº
        for entry in self.world_book_entries:
            if self._should_include_in_initial_build(entry):
                all_sources.append({
                    'type': 'world_book',
                    'data': entry,
                    'name': entry.name,
                    'order': entry.order,
                    'role': 'system',  # ä¸–ç•Œä¹¦é€šå¸¸æ˜¯systemè§’è‰²
                    'position': entry.position
                })
        
        # 3. æ”¶é›†å¯¹è¯å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
        for i, msg in enumerate(self.chat_history):
            all_sources.append({
                'type': 'chat_history',
                'data': msg,
                'name': f'chat_message_{i}',
                'order': 10000 + i,  # å¯¹è¯å†å²æ”¾åœ¨æœ€å
                'role': msg.role.value if hasattr(msg.role, 'value') else str(msg.role),
                'position': 'in-chat'
            })
        
        # 4. æŒ‰orderæ’åº
        all_sources.sort(key=lambda x: x['order'])
        
        print(f"ğŸ“‹ æ”¶é›†åˆ° {len(all_sources)} ä¸ªæ¶ˆæ¯æ¥æº")
        return all_sources
    
    def _evaluate_source_enabled(self, source, sandbox=None):
        """è¯„ä¼°æ¥æºçš„enabledçŠ¶æ€ï¼ˆæ”¯æŒä¼ å…¥æ²™ç›’è¿›è¡ŒåŠ¨æ€è¯„ä¼°ï¼‰"""
        source_type = source['type']
        data = source['data']
        
        if source_type in ['preset', 'world_book']:
            # é¢„è®¾å’Œä¸–ç•Œä¹¦æœ‰enabledå­—æ®µ
            return self._evaluate_enabled_with_sandbox(data, sandbox)
        else:
            # å¯¹è¯å†å²é»˜è®¤å¯ç”¨
            return True
    
    def _execute_source_code_block(self, source, sandbox):
        """æ‰§è¡Œæ¥æºçš„code_blockï¼ˆå¦‚æœæœ‰ï¼‰"""
        source_type = source['type']
        data = source['data']
        
        if source_type in ['preset', 'world_book'] and hasattr(data, 'code_block') and data.code_block and data.code_block.strip():
            print(f"ğŸ”„ æ‰§è¡Œ{source_type}ä»£ç å—: {source['name']}")
            
            try:
                if sandbox and hasattr(sandbox, 'execute_code'):
                    # ä½¿ç”¨Pythonæ²™ç›’æ‰§è¡Œ
                    scope_type = 'preset' if source_type == 'preset' else 'world'
                    result = sandbox.execute_code(data.code_block, scope_type=scope_type)
                    
                    if result.success:
                        print(f"âœ… {source_type}ä»£ç å—æ‰§è¡ŒæˆåŠŸ: {source['name']}")
                    else:
                        print(f"âŒ {source_type}ä»£ç å—æ‰§è¡Œå¤±è´¥: {result.error}")
                else:
                    # å›é€€åˆ°å®å¤„ç†å™¨æ‰§è¡Œ
                    if not hasattr(self, '_macro_processor') or self._macro_processor is None:
                        macro_context = self._build_macro_context()
                        try:
                            from ..utils.macro_processor import MacroProcessor
                        except ImportError:
                            from src.utils.macro_processor import MacroProcessor
                        self._macro_processor = MacroProcessor(macro_context)
                    
                    wrapped_code = f"{{{{python:{data.code_block}}}}}"
                    self._macro_processor._process_string(wrapped_code)
                    print(f"âœ… {source_type}ä»£ç å—æ‰§è¡ŒæˆåŠŸï¼ˆå®å¤„ç†å™¨ï¼‰: {source['name']}")
                    
            except Exception as e:
                print(f"âŒ {source_type}ä»£ç å—æ‰§è¡Œå¼‚å¸¸ ({source['name']}): {e}")
    
    def _process_source_content(self, source, sandbox):
        """å¤„ç†æ¥æºçš„contentå¹¶ç”ŸæˆOpenAIæ ¼å¼æ¶ˆæ¯"""
        source_type = source['type']
        data = source['data']
        
        if source_type == 'preset':
            # å¤„ç†é¢„è®¾å†…å®¹
            if not data.content:
                return []
            
            # å¤„ç†å®å’ŒPythonä»£ç 
            processed_content = self._process_content_macros(data.content, 'preset', sandbox)
            
            return [{
                "role": data.role,
                "content": processed_content,
                "_content_parts": [{"content": processed_content, "source_type": "preset"}]
            }]
            
        elif source_type == 'world_book':
            # å¤„ç†ä¸–ç•Œä¹¦å†…å®¹
            if not data.content:
                return []
                
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘
            if data.mode == 'conditional':
                # è¿™é‡Œå¯ä»¥æ·»åŠ å…³é”®è¯åŒ¹é…é€»è¾‘
                pass
            
            processed_content = self._process_content_macros(data.content, 'world', sandbox)
            
            # æ ¹æ®positionç¡®å®šrole
            role = 'system'  # ä¸–ç•Œä¹¦é»˜è®¤æ˜¯system
            if data.position in ['user', 'assistant']:
                role = data.position
                
            return [{
                "role": role,
                "content": processed_content,
                "_content_parts": [{"content": processed_content, "source_type": "world"}]
            }]
            
        elif source_type == 'chat_history':
            # å¤„ç†å¯¹è¯å†å²
            processed_content = self._process_content_macros(data.content, 'conversation', sandbox)
            
            return [{
                "role": source['role'],
                "content": processed_content,
                "_content_parts": [{"content": processed_content, "source_type": "conversation"}]
            }]
        
        return []
    
    def _process_content_macros(self, content, scope_type, sandbox):
        """å¤„ç†å†…å®¹ä¸­çš„å®å’ŒPythonä»£ç """
        if not content:
            return ""
            
        processed_content = content
        
        try:

            
            # 1. å¤„ç†ä¼ ç»Ÿå®
            if self._macro_processor is None:
                macro_context = self._build_macro_context()
                try:
                    from ..utils.macro_processor import MacroProcessor
                except ImportError:
                    from src.utils.macro_processor import MacroProcessor
                self._macro_processor = MacroProcessor(macro_context)
            processed_content = self._macro_processor._process_string(processed_content)
            
            # 2. å¤„ç†Pythonå®ï¼ˆä¼ å…¥å…±äº«çš„æ²™ç›’ï¼‰
            processed_content = self._process_python_macros(processed_content, scope_type, sandbox)
            
            # 3. æ‰§è¡Œå†…å®¹ä¸­çš„Pythonä»£ç å—
            if sandbox:
                processed_content = self._execute_python_blocks_in_content(processed_content, sandbox)
                

                
        except Exception as e:
            print(f"âš ï¸ å†…å®¹å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹: {e}")
            processed_content = content
            
        return processed_content
    
    def _merge_adjacent_openai_messages(self, messages):
        """åˆå¹¶ç›¸é‚»çš„ç›¸åŒrole OpenAIæ¶ˆæ¯"""
        if not messages:
            return []
            
        merged = []
        current_msg = None
        
        for msg in messages:
            if current_msg is None:
                current_msg = msg.copy()
            elif current_msg["role"] == msg["role"]:
                # åˆå¹¶ç›¸åŒroleçš„æ¶ˆæ¯
                current_msg["content"] += "\n\n" + msg["content"]
                
                # åˆå¹¶content_parts
                if "_content_parts" in current_msg and "_content_parts" in msg:
                    current_msg["_content_parts"].extend(msg["_content_parts"])
            else:
                # roleä¸åŒï¼Œä¿å­˜å½“å‰æ¶ˆæ¯å¹¶å¼€å§‹æ–°çš„
                merged.append(current_msg)
                current_msg = msg.copy()
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ¶ˆæ¯
        if current_msg is not None:
            merged.append(current_msg)
            
        return merged


def create_chat_manager(character_data: Dict[str, Any], preset_data: Dict[str, Any]) -> ChatHistoryManager:
    """åˆ›å»ºå¹¶åˆå§‹åŒ–ChatHistoryManager"""
    manager = ChatHistoryManager()
    
    # å­˜å‚¨è§’è‰²æ•°æ®
    manager.character_data = character_data
    
    # åŠ è½½ä¸–ç•Œä¹¦
    if "world_book" in character_data:
        manager.load_world_book(character_data["world_book"])
    
    # åŠ è½½é¢„è®¾
    manager.load_presets(preset_data)
    
    # æ‰§è¡Œè§’è‰²çš„code_blockï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    manager._execute_character_code_block()
    
    return manager


# ç¤ºä¾‹ä½¿ç”¨å‡½æ•°
def demo_usage():
    """æ¼”ç¤ºç”¨æ³•"""
    # æ¨¡æ‹Ÿè§’è‰²æ•°æ®
    character_data = {
        "name": "æµ‹è¯•è§’è‰²",
        "world_book": {
            "entries": [
                {
                    "id": 1,
                    "name": "test_entry",
                    "enabled": True,
                    "mode": "always",
                    "position": "system",
                    "keys": ["hello"],
                    "content": "This is a test world book entry."
                }
            ]
        }
    }
    
    # æ¨¡æ‹Ÿé¢„è®¾æ•°æ®
    preset_data = {
        "prompts": [
            {
                "identifier": "test_preset",
                "name": "Test Preset",
                "enable": True,
                "role": "system",
                "position": "in-chat",
                "content": "You are a helpful assistant.",
                "depth": 2
            }
        ]
    }
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = create_chat_manager(character_data, preset_data)
    
    # æ·»åŠ å¯¹è¯
    manager.add_user_message("Hello there!")
    manager.add_assistant_message("Hi! How can I help you?")
    
    # è·å–OpenAIæ ¼å¼çš„æ¶ˆæ¯
    messages = manager.to_openai_messages()
    print("OpenAIæ ¼å¼æ¶ˆæ¯:")
    for msg in messages:
        print(f"  {msg['role']}: {msg['content'][:50]}...")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = manager.get_statistics()
    print(f"\nç»Ÿè®¡ä¿¡æ¯: {stats}")


if __name__ == "__main__":
    demo_usage()
