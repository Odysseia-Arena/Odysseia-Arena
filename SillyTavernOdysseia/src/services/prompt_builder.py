#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æç¤ºè¯æ„å»ºå™¨ (Prompt Builder)

è´Ÿè´£æ„å»ºå’Œåˆå¹¶æœ€ç»ˆçš„æç¤ºè¯ï¼ŒåŒ…æ‹¬ï¼š
- æ’åºå’Œåˆå¹¶é¢„è®¾ (presets)
- æ’åºå’Œåˆå¹¶ä¸–ç•Œä¹¦æ¡ç›® (world book entries)
- åˆå¹¶èŠå¤©å†å² (chat history)
- åº”ç”¨åŠ¨æ€ `enabled` åˆ¤æ–­
- æ‰§è¡Œä»£ç å—
- åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢è§„åˆ™
"""

from __future__ import annotations

import re
from typing import Any, Dict, List, Optional, Union, Tuple

from .data_models import ChatMessage, MessageRole, PresetPrompt, WorldBookEntry
from .dynamic_evaluator import DynamicEvaluator
from .code_executor import CodeExecutor
from .macro_manager import MacroManager
from .regex_rule_manager import RegexRuleManager


class PromptBuilder:
    """æ„å»ºæœ€ç»ˆæç¤ºè¯çš„ä¸“ç”¨ç±»"""

    def __init__(
        self,
        evaluator: DynamicEvaluator,
        code_executor: CodeExecutor,
        macro_manager: MacroManager,
        character_data: Dict[str, Any],
        persona_data: Dict[str, Any],
        regex_rule_manager: RegexRuleManager = None,
    ):
        self.evaluator = evaluator
        self.code_executor = code_executor
        self.macro_manager = macro_manager
        self.character_data = character_data
        self.persona_data = persona_data
        self.regex_rule_manager = regex_rule_manager
        
        # ä¿å­˜ä¸‰ç§ä¸åŒé˜¶æ®µçš„æç¤ºè¯ç¼“å­˜
        self.raw_prompt: List[Dict[str, Any]] = []  # åŸå§‹æ ¼å¼ï¼ˆæœªå¤„ç†å®å’Œæ­£åˆ™ï¼‰
        self.processed_prompt: List[Dict[str, Any]] = []  # å¤„ç†åçš„æ ¼å¼ï¼ˆæ‰§è¡Œäº†å®å’Œæ­£åˆ™ï¼‰
        self.clean_prompt: List[Dict[str, str]] = []  # çº¯å‡€æ ¼å¼ï¼ˆåˆå¹¶åçš„æ ‡å‡†æ ¼å¼ï¼‰

    def build_final_prompt(
        self,
        chat_history: List[ChatMessage],
        world_book_entries: List[WorldBookEntry],
        preset_prompts: List[PresetPrompt],
        triggered_entries: set[int],
        view_type: str = "processed"
    ) -> List[Dict[str, str]]:
        """
        åŠ¨æ€æ„å»ºæœ€ç»ˆçš„æç¤ºè¯ - æ–°çš„ä¸‰é˜¶æ®µå¤„ç†é€»è¾‘

        æ–°çš„å¤„ç†æµç¨‹ï¼š
        1. RAW é˜¶æ®µï¼šç”Ÿæˆæœ€åŸå§‹çš„æç¤ºè¯ï¼Œæœªæ‰§è¡Œå®å’Œæ­£åˆ™ï¼Œä¸¤ä¸ªè§†å›¾å®Œå…¨ä¸€æ ·
        2. PROCESSED é˜¶æ®µï¼šåœ¨rawåŸºç¡€ä¸ŠæŒ‰åºå¤„ç† - å®å¤„ç†å‰æ­£åˆ™ â†’ å®ã€ä»£ç æ‰§è¡Œ â†’ å®å¤„ç†åæ­£åˆ™
        3. CLEAN é˜¶æ®µï¼šåœ¨processedåŸºç¡€ä¸Šè¿›è¡Œåˆå¹¶æ“ä½œ

        Args:
            chat_history: èŠå¤©å†å²è®°å½•
            world_book_entries: ä¸–ç•Œä¹¦æ¡ç›®åˆ—è¡¨
            preset_prompts: é¢„è®¾æç¤ºè¯åˆ—è¡¨
            triggered_entries: å·²è§¦å‘çš„æ¡ç›®IDé›†åˆ
            view_type: è¦è¿”å›çš„è§†å›¾ç±»å‹ï¼Œå¯é€‰å€¼:
                "raw" - åŸå§‹è§†å›¾ï¼ˆæœªå¤„ç†å®å’Œæ­£åˆ™ï¼‰
                "processed" - å¤„ç†åçš„è§†å›¾ï¼ˆæ‰§è¡Œäº†å®å’Œæ­£åˆ™ï¼‰
                "clean" - çº¯å‡€è§†å›¾ï¼ˆåˆå¹¶åçš„æ ‡å‡†æ ¼å¼ï¼‰
        
        Returns:
            æ ¹æ®view_typeè¿”å›ç›¸åº”æ ¼å¼çš„æç¤ºè¯åˆ—è¡¨
        """
        print("ğŸ”„ å¼€å§‹åŠ¨æ€æ„å»ºæç¤ºè¯ - æ–°ä¸‰é˜¶æ®µå¤„ç†")

        # æ›´æ–°ä¾èµ–é¡¹ä¸­çš„èŠå¤©å†å²
        self.macro_manager.update_chat_history(chat_history)
        
        # æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
        self.evaluator.clear_enabled_cache(world_book_entries)
        self.evaluator.clear_enabled_cache(preset_prompts)

        # æ”¶é›†æ‰€æœ‰æ¶ˆæ¯æ¥æºå¹¶æ’åº
        all_sources = self._collect_all_sources(
            chat_history, world_book_entries, preset_prompts, triggered_entries
        )

        # ===== é˜¶æ®µ1ï¼šRAW - ç”ŸæˆåŸå§‹æç¤ºè¯ =====
        print("ğŸ“ é˜¶æ®µ1ï¼šç”ŸæˆRAWæç¤ºè¯ï¼ˆæœªå¤„ç†å®å’Œæ­£åˆ™ï¼‰")
        raw_messages = self._build_raw_messages(all_sources, world_book_entries)
        
        # ç”Ÿæˆä¸¤ä¸ªè§†å›¾çš„RAWæç¤ºè¯ï¼ˆå®Œå…¨ä¸€æ ·ï¼‰
        self.raw_prompt = [msg.to_openai_format() for msg in raw_messages]
        
        if view_type == "raw":
            print(f"ğŸ‰ RAWé˜¶æ®µå®Œæˆï¼ŒåŒ…å« {len(self.raw_prompt)} ä¸ªæ¶ˆæ¯å—")
            return self.raw_prompt

        # ===== é˜¶æ®µ2ï¼šPROCESSED - æ‰§è¡Œå®å’Œæ­£åˆ™å¤„ç† =====
        print("âš™ï¸ é˜¶æ®µ2ï¼šæ‰§è¡ŒPROCESSEDå¤„ç†ï¼ˆå®å¤„ç†å‰æ­£åˆ™ â†’ å®ã€ä»£ç æ‰§è¡Œ â†’ å®å¤„ç†åæ­£åˆ™ï¼‰")
        processed_messages = self._build_processed_messages(raw_messages, all_sources, world_book_entries)
        
        # ç”Ÿæˆä¸¤ä¸ªè§†å›¾çš„PROCESSEDæç¤ºè¯
        self.processed_prompt = [msg.to_openai_format() for msg in processed_messages]
        
        if view_type == "processed":
            print(f"ğŸ‰ PROCESSEDé˜¶æ®µå®Œæˆï¼ŒåŒ…å« {len(self.processed_prompt)} ä¸ªæ¶ˆæ¯å—")
            return self.processed_prompt

        # ===== é˜¶æ®µ3ï¼šCLEAN - åˆå¹¶æ“ä½œ =====
        print("ğŸ§¹ é˜¶æ®µ3ï¼šæ‰§è¡ŒCLEANå¤„ç†ï¼ˆåˆå¹¶ç›¸é‚»æ¶ˆæ¯ï¼‰")
        clean_messages = self._build_clean_messages(processed_messages)
        
        # ç”Ÿæˆä¸¤ä¸ªè§†å›¾çš„CLEANæç¤ºè¯
        self.clean_prompt = [
            {k: v for k, v in msg.to_openai_format().items() if not k.startswith('_')}
            for msg in clean_messages
        ]
        
        print(f"ğŸ‰ CLEANé˜¶æ®µå®Œæˆï¼ŒåŒ…å« {len(self.clean_prompt)} ä¸ªæ¶ˆæ¯å—")
        return self.clean_prompt

    def _build_raw_messages(self, all_sources: List[Dict[str, Any]], world_book_entries: List[WorldBookEntry]) -> List[ChatMessage]:
        """
        æ„å»ºRAWé˜¶æ®µçš„æ¶ˆæ¯ - åªè¿›è¡ŒåŸºç¡€çš„enabledè¯„ä¼°ï¼Œä¸æ‰§è¡Œå®å’Œæ­£åˆ™
        
        Args:
            all_sources: æ‰€æœ‰æ¶ˆæ¯æ¥æºåˆ—è¡¨
            world_book_entries: ä¸–ç•Œä¹¦æ¡ç›®åˆ—è¡¨
            
        Returns:
            RAWé˜¶æ®µçš„æ¶ˆæ¯åˆ—è¡¨
        """
        raw_messages: List[ChatMessage] = []
        
        for source in all_sources:
            item = source["data"]
            source_type = source["type"]
            
            # åªè¿›è¡Œenabledè¯„ä¼°ï¼Œä¸æ‰§è¡Œcode_blockå’Œå®å¤„ç†
            if not isinstance(item, ChatMessage):
                if not self.evaluator.evaluate_enabled(item):
                    print(f"â­ï¸  è·³è¿‡ç¦ç”¨æ¡ç›®: {getattr(item, 'name', '') or getattr(item, 'identifier', '')} ({source_type})")
                    continue
            
            # ä¸ºèŠå¤©å†å²æ¶ˆæ¯ç›´æ¥åˆ›å»ºæ¶ˆæ¯
            if source_type == "chat_history":
                raw_messages.append(item)
                continue
            
            # ä¸ºé¢„è®¾å’Œä¸–ç•Œä¹¦åˆ›å»ºåŸå§‹æ¶ˆæ¯ï¼ˆä¸å¤„ç†å®ï¼‰
            content = self._resolve_special_content(item, world_book_entries)
            if not content or not content.strip():
                continue
            
            role = MessageRole(source["role"]) if isinstance(source["role"], str) else source["role"]
            message = ChatMessage(role=role)
            
            # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œåªä¸ºé¢„è®¾å’Œä¸–ç•Œä¹¦è®¾ç½®source_name
            source_name = None
            if source_type in ["preset", "world"]:
                source_name = getattr(item, 'name', '')
            
            # æ„å»ºsource_id
            base_id = getattr(item, 'identifier', '') or str(getattr(item, 'id', ''))
            position = getattr(item, 'position', '')
            
            if source_type == "preset" and position:
                source_id = f"{base_id}:{position}"
            else:
                source_id = base_id
            
            message.add_content_part(
                content=content,  # åŸå§‹å†…å®¹ï¼Œæœªå¤„ç†å®
                source_type=source_type,
                source_id=source_id,
                source_name=source_name
            )
            raw_messages.append(message)
        
        return raw_messages

    def _build_processed_messages(self, raw_messages: List[ChatMessage], all_sources: List[Dict[str, Any]], world_book_entries: List[WorldBookEntry]) -> List[ChatMessage]:
        """
        æ„å»ºPROCESSEDé˜¶æ®µçš„æ¶ˆæ¯ - é‡æ–°å¤„ç†æ‰€æœ‰æºï¼Œæ‰§è¡Œå®Œæ•´çš„å¤„ç†æµç¨‹
        
        å¤„ç†é¡ºåºï¼šå®å¤„ç†å‰æ­£åˆ™ â†’ å®ã€ä»£ç æ‰§è¡Œ â†’ å®å¤„ç†åæ­£åˆ™
        
        Args:
            raw_messages: RAWé˜¶æ®µçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆç”¨äºå‚è€ƒï¼‰
            all_sources: æ‰€æœ‰æ¶ˆæ¯æ¥æºåˆ—è¡¨
            world_book_entries: ä¸–ç•Œä¹¦æ¡ç›®åˆ—è¡¨
            
        Returns:
            PROCESSEDé˜¶æ®µçš„æ¶ˆæ¯åˆ—è¡¨
        """
        processed_messages: List[ChatMessage] = []
        
        for source in all_sources:
            item = source["data"]
            source_type = source["type"]
            depth = source.get("depth")
            order = source.get("order")

            # è¯„ä¼°enabledçŠ¶æ€ (èŠå¤©å†å²æ¶ˆæ¯æ€»æ˜¯å¯ç”¨)
            if not isinstance(item, ChatMessage):
                if not self.evaluator.evaluate_enabled(item):
                    print(f"â­ï¸  è·³è¿‡ç¦ç”¨æ¡ç›®: {getattr(item, 'name', '') or getattr(item, 'identifier', '')} ({source_type})")
                    continue

            # æ‰§è¡Œcode_block (èŠå¤©å†å²æ¶ˆæ¯æ²¡æœ‰code_block)
            if not isinstance(item, ChatMessage) and hasattr(item, "code_block") and item.code_block:
                scope = "preset" if source_type == "preset" else "world"
                self.code_executor.execute_code_block(item.code_block, item.name, scope)
                # æ‰§è¡Œä»£ç åï¼Œæ¸…ç©ºç¼“å­˜ï¼Œä»¥ä¾¿åç»­è¯„ä¼°ä½¿ç”¨æœ€æ–°çŠ¶æ€
                self.evaluator.clear_enabled_cache(world_book_entries)
                self.evaluator.clear_enabled_cache([])  # æ¸…ç©ºé¢„è®¾ç¼“å­˜

            # å¤„ç†æ¶ˆæ¯å†…å®¹
            message = self._process_source_content_for_processed(source, world_book_entries)
            if message:
                processed_messages.append(message)
        
        return processed_messages

    def _build_clean_messages(self, processed_messages: List[ChatMessage]) -> List[ChatMessage]:
        """
        æ„å»ºCLEANé˜¶æ®µçš„æ¶ˆæ¯ - åœ¨PROCESSEDåŸºç¡€ä¸Šè¿›è¡Œåˆå¹¶æ“ä½œ
        
        Args:
            processed_messages: PROCESSEDé˜¶æ®µçš„æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            CLEANé˜¶æ®µçš„æ¶ˆæ¯åˆ—è¡¨
        """
        # åˆå¹¶ç›¸é‚»çš„ç›¸åŒè§’è‰²æ¶ˆæ¯
        return self._merge_adjacent_roles(processed_messages)

    def _process_source_content_for_processed(self, source: Dict[str, Any], world_book_entries: List[WorldBookEntry]) -> Optional[ChatMessage]:
        """
        ä¸ºPROCESSEDé˜¶æ®µå¤„ç†å•ä¸ªæ¥æºçš„å†…å®¹
        
        æŒ‰ç…§æ–°çš„å¤„ç†é¡ºåºï¼šå…ˆæ„å»ºæ¶ˆæ¯ â†’ æ£€æŸ¥æ˜¯å¦åŒ…å«relative â†’ åº”ç”¨æ­£åˆ™å¤„ç†
        
        Args:
            source: æ¶ˆæ¯æºä¿¡æ¯
            world_book_entries: ä¸–ç•Œä¹¦æ¡ç›®åˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„ChatMessageï¼Œå¦‚æœå†…å®¹ä¸ºç©ºåˆ™è¿”å›None
        """
        item = source["data"]
        source_type = source["type"]
        depth = source.get("depth")
        order = source.get("order")
        
        if source_type == "chat_history":
            # èŠå¤©å†å²æ¶ˆæ¯ï¼šå…ˆå…‹éš†ï¼Œç„¶åæ£€æŸ¥æ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†
            message = self._clone_chat_message(item)
            
            # ğŸ”§ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯ assistant_response_processingï¼Œéœ€è¦è¿›è¡Œå®å¤„ç†
            openai_format = message.to_openai_format()
            source_identifiers = openai_format.get('_source_identifiers', [])
            is_assistant_response_processing = any(
                isinstance(sid, str) and 'assistant_response_processing' in sid 
                for sid in source_identifiers
            )
            
            if is_assistant_response_processing:
                # å¯¹ assistant_response_processing æ¶ˆæ¯è¿›è¡Œå®Œæ•´çš„å®å’Œæ­£åˆ™å¤„ç†
                for content_part in message.content_parts:
                    original_content = content_part.content
                    
                    # åº”ç”¨å®å¤„ç†å‰çš„æ­£åˆ™ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    processed_content = original_content
                    if self.regex_rule_manager and self._should_apply_regex_to_message(message):
                        processed_content = self._apply_regex_before_macro_skip(processed_content, "conversation", depth, order)
                        processed_content = self._apply_regex_before_macro_include(processed_content, "conversation", depth, order)
                    
                    # å¤„ç†å®
                    processed_content = self.macro_manager.process_string(processed_content, 'conversation')
                    
                    # åº”ç”¨å®å¤„ç†åçš„æ­£åˆ™ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if self.regex_rule_manager and self._should_apply_regex_to_message(message):
                        processed_content = self.regex_rule_manager.apply_regex_to_content(
                            content=processed_content,
                            source_type="conversation",
                            depth=depth,
                            order=order,
                            placement="after_macro"
                        )
                    
                    # æ›´æ–°å†…å®¹
                    content_part.content = processed_content
            else:
                # æ™®é€šèŠå¤©å†å²æ¶ˆæ¯ï¼šåªåº”ç”¨æ­£åˆ™
                if self.regex_rule_manager and self._should_apply_regex_to_message(message):
                    self._apply_regex_to_chat_message(message, depth, order)
            
            return message

        # è·å–åŸå§‹å†…å®¹
        content = self._resolve_special_content(item, world_book_entries)
        if not content or not content.strip():
            return None

        # å…ˆåˆ›å»ºåŸºæœ¬æ¶ˆæ¯ï¼ˆä¸å¤„ç†æ­£åˆ™ï¼‰
        role = MessageRole(source["role"]) if isinstance(source["role"], str) else source["role"]
        message = ChatMessage(role=role)
        
        # æ„å»ºsource_idï¼ˆåŒ…å«positionä¿¡æ¯ï¼‰
        base_id = getattr(item, 'identifier', '') or str(getattr(item, 'id', ''))
        position = getattr(item, 'position', '')
        
        if source_type == "preset" and position:
            source_id = f"{base_id}:{position}"  # æ ¼å¼ï¼šidentifier:position
        else:
            source_id = base_id
        
        # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œåªä¸ºé¢„è®¾å’Œä¸–ç•Œä¹¦è®¾ç½®source_name
        source_name = None
        if source_type in ["preset", "world"]:
            source_name = getattr(item, 'name', '')
        
        message.add_content_part(
            content=content,  # å…ˆæ·»åŠ åŸå§‹å†…å®¹
            source_type=source_type,
            source_id=source_id,
            source_name=source_name
        )
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ­£åˆ™å¤„ç†ï¼ˆåŸºäº_source_identifiersä¸­çš„:relativeåç¼€ï¼‰
        if not self._should_apply_regex_to_message(message):
            # å¦‚æœåŒ…å«relativeï¼Œåªå¤„ç†å®ï¼Œè·³è¿‡æ­£åˆ™
            scope = "preset" if source_type == "preset" else "world"
            processed_content = self.macro_manager.process_string(content, scope)
            
            # æ›´æ–°æ¶ˆæ¯å†…å®¹
            message.content_parts[0].content = processed_content
            return message if processed_content.strip() else None
        
        # å¯¹äºérelativeçš„æ¶ˆæ¯ï¼ŒæŒ‰å®Œæ•´é¡ºåºå¤„ç†
        if self.regex_rule_manager:
            # é˜¶æ®µ1ï¼šåº”ç”¨å®å¤„ç†å‰çš„æ­£åˆ™æ›¿æ¢
            content = self._apply_regex_before_macro_skip(content, source_type, depth, order)
            content = self._apply_regex_before_macro_include(content, source_type, depth, order)

        # é˜¶æ®µ2ï¼šå¤„ç†å®
        scope = "preset" if source_type == "preset" else "world"
        processed_content = self.macro_manager.process_string(content, scope)

        # é˜¶æ®µ3ï¼šåº”ç”¨å®å¤„ç†åçš„æ­£åˆ™æ›¿æ¢
        if self.regex_rule_manager:
            processed_content = self.regex_rule_manager.apply_regex_to_content(
                content=processed_content,
                source_type=source_type,
                depth=depth,
                order=order,
                placement="after_macro"
            )

        # æ›´æ–°æ¶ˆæ¯å†…å®¹
        if processed_content.strip():
            message.content_parts[0].content = processed_content
            return message
        else:
            return None



    def _should_apply_regex_to_message(self, message: ChatMessage) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å¯¹æ¶ˆæ¯åº”ç”¨æ­£åˆ™è§„åˆ™
        
        æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼š
        1. æ£€æŸ¥_source_identifiersä¸­æ˜¯å¦åŒ…å«":relative"ç»“å°¾çš„æ ‡è¯†ç¬¦
        2. å¦‚æœåŒ…å«relativeï¼Œè·³è¿‡æ­£åˆ™å¤„ç†
        3. æ­£åˆ™è„šæœ¬æŒ‡å®šçš„ä½œç”¨å¯¹è±¡ä¸ä¼šåŒ…æ‹¬å«æœ‰relativeçš„æ¡ç›®
        
        Args:
            message: ChatMessageå¯¹è±¡
            
        Returns:
            æ˜¯å¦åº”è¯¥åº”ç”¨æ­£åˆ™
        """
        # è½¬æ¢ä¸ºOpenAIæ ¼å¼ä»¥è·å–_source_identifiers
        openai_msg = message.to_openai_format()
        
        # æ£€æŸ¥_source_identifiersä¸­æ˜¯å¦åŒ…å«":relative"ç»“å°¾çš„æ ‡è¯†ç¬¦
        source_identifiers = openai_msg.get("_source_identifiers", [])
        for identifier in source_identifiers:
            if isinstance(identifier, str) and identifier.endswith(":relative"):
                return False  # è·³è¿‡åŒ…å«relativeæ ‡è¯†ç¬¦çš„æ¶ˆæ¯ï¼ˆå¦‚worldInfoAfter:relativeï¼‰
        
        return True  # é»˜è®¤åº”ç”¨æ­£åˆ™

    def _collect_all_sources(
        self,
        chat_history: List[ChatMessage],
        world_book_entries: List[WorldBookEntry],
        preset_prompts: List[PresetPrompt],
        triggered_entries: set[int],
    ) -> List[Dict[str, Any]]:
        """æ”¶é›†æ‰€æœ‰æ¶ˆæ¯æ¥æºå¹¶æŒ‰orderæ’åº"""
        sources = []

        # æ”¶é›†é¢„è®¾å’Œä¸–ç•Œä¹¦
        for item in preset_prompts + world_book_entries:
            # 'relative' ç±»å‹çš„é¢„è®¾å’Œ 'always' ç±»å‹çš„ä¸–ç•Œä¹¦åœ¨è¿™é‡Œå¤„ç†
            if isinstance(item, PresetPrompt) and item.position != "relative":
                continue
            if isinstance(item, WorldBookEntry) and item.mode not in ["always", "before_char", "after_char"]:
                 if item.mode != 'conditional' or item.id not in triggered_entries:
                    continue

            sources.append({
                "data": item,
                "type": "preset" if isinstance(item, PresetPrompt) else "world",
                "order": item.order or 100,
                "role": item.role if hasattr(item, "role") else self._map_wb_pos_to_role(item.position),
                "depth": item.depth or 0,
                "position": getattr(item, "position", None),  # ç›´æ¥æ·»åŠ positionä¿¡æ¯
                "internal_order": len(sources) # ä¿æŒåŸå§‹é¡ºåº
            })

        # æ’åº
        sources = self._sort_by_order_rules(sources)

        # åˆå¹¶èŠå¤©å†å²å’Œ in-chat é¢„è®¾
        in_chat_items = [
            {"data": msg, "type": "chat_history", "depth": 10000 + i, "order": 10000 + i, "role": msg.role, "internal_order": 10000 + i}
            for i, msg in enumerate(chat_history)
        ]
        in_chat_items.extend([
            {
                "data": p,
                "type": "preset",
                "depth": p.depth or 0,
                "order": p.order or 100,
                "role": MessageRole(p.role),
                "position": p.position,  # æ·»åŠ positionä¿¡æ¯
                "internal_order": len(sources) + i
            }
            for i, p in enumerate(preset_prompts) if p.position == "in-chat"
        ])
        
        # å¯¹ in-chat å†…å®¹è¿›è¡Œæ’åº
        sorted_in_chat = self._sort_by_order_rules(in_chat_items)

        # å°†èŠå¤©å†å²å’Œ in-chat é¢„è®¾æ’å…¥åˆ° 'chatHistory' å ä½ç¬¦çš„ä½ç½®
        final_sources = []
        chat_history_inserted = False
        for source in sources:
            if isinstance(source["data"], PresetPrompt) and source["data"].identifier == "chatHistory":
                final_sources.extend(sorted_in_chat)
                chat_history_inserted = True
            else:
                final_sources.append(source)
        
        if not chat_history_inserted:
             final_sources.extend(sorted_in_chat)

        return final_sources



    def _resolve_special_content(self, item: Union[PresetPrompt, WorldBookEntry], world_book_entries: List[WorldBookEntry]) -> str:
        """è§£æç‰¹æ®Šidentifierçš„å†…å®¹æˆ–è¿”å›åŸå§‹content"""
        if isinstance(item, WorldBookEntry):
            return item.content

        identifier = item.identifier
        if identifier == "worldInfoBefore":
            return self._get_world_info_content(world_book_entries, "before_char")
        elif identifier == "worldInfoAfter":
            return self._get_world_info_content(world_book_entries, "after_char")
        elif identifier == "charDescription":
            return self.character_data.get("description", "")
        elif identifier == "personaDescription":
            return self.persona_data.get("description", "")
        
        # 'chatHistory' åœ¨ _collect_all_sources ä¸­ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œè¿”å›ç©º
        if identifier == "chatHistory":
            return ""

        return item.content or ""

    def _merge_adjacent_roles(self, messages: List[ChatMessage]) -> List[ChatMessage]:
        """åˆå¹¶ç›¸é‚»çš„ç›¸åŒroleå—"""
        if not messages:
            return []
        
        merged = [messages[0]]
        for i in range(1, len(messages)):
            if messages[i].role == merged[-1].role:
                # åˆå¹¶å†…å®¹éƒ¨åˆ†
                merged[-1].content_parts.extend(messages[i].content_parts)
            else:
                merged.append(messages[i])
        
        # è¿‡æ»¤æ‰åˆå¹¶åå†…å®¹ä»ç„¶ä¸ºç©ºçš„æ¶ˆæ¯
        return [msg for msg in merged if msg.get_merged_content().strip()]

    def _sort_by_order_rules(self, entries: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æŒ‰ç…§æ¬¡åºè§„åˆ™æ’åº"""
        def sort_key(entry):
            depth = entry.get("depth", 0) or 0
            order = entry.get("order", 100) or 100
            role_val = entry.get("role")
            role = role_val.value if hasattr(role_val, 'value') else str(role_val)
            internal_order = entry.get("internal_order", 0)
            
            return (-depth, order, self._get_role_priority(role), internal_order)
        
        return sorted(entries, key=sort_key)

    def _get_role_priority(self, role: str) -> int:
        """è·å–roleçš„ä¼˜å…ˆçº§"""
        role_priority = {"assistant": 0, "user": 1, "system": 2}
        return role_priority.get(role, 2)

    def _map_wb_pos_to_role(self, position: str) -> MessageRole:
        """å°†ä¸–ç•Œä¹¦çš„positionæ˜ å°„åˆ°MessageRole"""
        mapping = {
            "assistant": MessageRole.ASSISTANT,
            "user": MessageRole.USER,
        }
        return mapping.get(position, MessageRole.SYSTEM)

    def _apply_regex_before_macro_skip(self, content: str, source_type: str, depth: Optional[int] = None, order: Optional[int] = None, view: str = "original") -> str:
        """
        åº”ç”¨å®å¤„ç†å‰çš„æ­£åˆ™æ›¿æ¢ï¼Œä½†è·³è¿‡å®çš„å†…éƒ¨å­—ç¬¦
        
        è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„å¤„ç†ï¼šå…ˆæ‰¾åˆ°æ‰€æœ‰å®ï¼Œä¿å­˜å®ƒä»¬çš„ä½ç½®ï¼Œ
        å°†å®æ›¿æ¢ä¸ºä¸´æ—¶æ ‡è®°ï¼Œåº”ç”¨æ­£åˆ™ï¼Œç„¶åå°†å®æ”¾å›åŸä½ã€‚
        """
        if not self.regex_rule_manager or not content:
            return content
            
        # 1. æ‰¾åˆ°æ‰€æœ‰å®
        macro_pattern = r'\{\{([^{}]*)\}\}'
        macros = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å®ï¼Œè®°å½•ä½ç½®å’Œå†…å®¹
        for match in re.finditer(macro_pattern, content):
            macros.append({
                "start": match.start(),
                "end": match.end(),
                "content": match.group(0)
            })
        
        if not macros:
            # æ²¡æœ‰å®ï¼Œç›´æ¥åº”ç”¨æ­£åˆ™
            return self.regex_rule_manager.apply_regex_to_content(
                content=content,
                source_type=source_type,
                depth=depth,
                order=order,
                placement="before_macro_skip",
                view=view
            )
        
        # 2. ç”¨å ä½ç¬¦æ›¿æ¢å®
        placeholder_pattern = "___MACRO_PLACEHOLDER_{}_____"
        result = content
        offset = 0
        
        for i, macro in enumerate(macros):
            placeholder = placeholder_pattern.format(i)
            start = macro["start"] + offset
            end = macro["end"] + offset
            
            # æ›¿æ¢å®ä¸ºå ä½ç¬¦
            result = result[:start] + placeholder + result[end:]
            
            # æ›´æ–°åç§»é‡
            offset += len(placeholder) - (end - start)
        
        # 3. åº”ç”¨æ­£åˆ™æ›¿æ¢
        result = self.regex_rule_manager.apply_regex_to_content(
            content=result,
            source_type=source_type,
            depth=depth,
            order=order,
            placement="before_macro_skip",
            view=view
        )
        
        # 4. å°†å®æ”¾å›
        for i, macro in enumerate(macros):
            placeholder = placeholder_pattern.format(i)
            result = result.replace(placeholder, macro["content"])
        
        return result

    def _apply_regex_before_macro_include(self, content: str, source_type: str, depth: Optional[int] = None, order: Optional[int] = None, view: str = "original") -> str:
        """
        åº”ç”¨å®å¤„ç†å‰çš„æ­£åˆ™æ›¿æ¢ï¼ŒåŒ…æ‹¬å®çš„å†…éƒ¨å­—ç¬¦
        
        è¿™ä¸ªç®€å•è®¸å¤šï¼Œç›´æ¥åº”ç”¨æ­£åˆ™å³å¯ã€‚
        """
        if not self.regex_rule_manager:
            return content
            
        return self.regex_rule_manager.apply_regex_to_content(
            content=content,
            source_type=source_type,
            depth=depth,
            order=order,
            placement="before_macro_include",
            view=view
        )
        
    def _apply_regex_to_chat_message(self, message: ChatMessage, depth: Optional[int] = None, order: Optional[int] = None, view: str = "original") -> None:
        """
        å¯¹èŠå¤©æ¶ˆæ¯çš„æ¯ä¸ªå†…å®¹éƒ¨åˆ†åº”ç”¨æ­£åˆ™è§„åˆ™
        
        ä¿®æ”¹æ˜¯å°±åœ°è¿›è¡Œçš„ï¼Œä¸è¿”å›æ–°æ¶ˆæ¯ã€‚
        """
        if not self.regex_rule_manager or not message or not message.content_parts:
            return
            
        # å¯¹æ¯ä¸ªå†…å®¹éƒ¨åˆ†åˆ†åˆ«åº”ç”¨æ­£åˆ™è§„åˆ™
        for part in message.content_parts:
            # åªå¤„ç†å®å¤„ç†åé˜¶æ®µï¼Œå› ä¸ºèŠå¤©å†å²çš„å®å·²ç»åœ¨å‘é€æ—¶å¤„ç†è¿‡äº†
            processed_content = self.regex_rule_manager.apply_regex_to_content_part(
                content_part=part,
                depth=depth,
                order=order,
                placement="after_macro",
                view=view
            )
            
            # æ›´æ–°å†…å®¹éƒ¨åˆ†
            part.content = processed_content
    
        
        
    def _clone_chat_message(self, message: ChatMessage) -> ChatMessage:
        """åˆ›å»ºèŠå¤©æ¶ˆæ¯çš„æ·±åº¦å‰¯æœ¬"""
        new_message = ChatMessage(role=message.role)
        
        # å¤åˆ¶å†…å®¹éƒ¨åˆ†
        for part in message.content_parts:
            new_message.add_content_part(
                content=part.content,
                source_type=part.source_type,
                source_id=part.source_id,
                source_name=part.source_name
            )
            
        # å¤åˆ¶å…ƒæ•°æ®
        new_message.metadata = message.metadata.copy() if message.metadata else {}
        
        return new_message

    def _get_world_info_content(self, world_book_entries: List[WorldBookEntry], position: str) -> str:
        """è·å–ç‰¹å®šä½ç½®çš„ä¸–ç•Œä¹¦å†…å®¹"""
        entries = [
            entry for entry in world_book_entries if entry.position == position and self.evaluator.evaluate_enabled(entry)
        ]
        
        # æ’åº
        sorted_entries = self._sort_by_order_rules([
            {
                "data": entry,
                "type": "world",
                "order": entry.order or 100,
                "role": self._map_wb_pos_to_role(entry.position),
                "depth": entry.depth or 0,
                "internal_order": i
            } for i, entry in enumerate(entries)
        ])
        
        content_list = [entry["data"].content for entry in sorted_entries if entry["data"].content.strip()]
        return "\n".join(content_list)
