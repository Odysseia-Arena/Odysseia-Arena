#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç»Ÿä¸€APIæ¥å£æ¨¡å—

æä¾›ç®€æ´çš„Pythonå‡½æ•°æ¥å£ï¼Œå°è£…å®Œæ•´çš„èŠå¤©ç³»ç»ŸåŠŸèƒ½ï¼š
- è¾“å…¥æ¥å£ï¼šå¤„ç†é…ç½®IDã€ç”¨æˆ·è¾“å…¥ï¼Œè¿”å›æœ€ç»ˆæç¤ºè¯
- è¾“å‡ºæ¥å£ï¼šè¿”å›æ¥æºIDå’Œå¤„ç†åçš„æç¤ºè¯
- é›†æˆå®å¤„ç†ã€Pythonæ²™ç›’ã€ä¸–ç•Œä¹¦ç­‰å®Œæ•´åŠŸèƒ½
"""

from __future__ import annotations

import uuid
from typing import Any, Dict, List, Optional, Union, Tuple
from dataclasses import dataclass, field
from datetime import datetime

# å¯¼å…¥ç°æœ‰æœåŠ¡æ¨¡å—
from .services.config_manager import ConfigManager, create_config_manager
from .services.chat_history_manager import ChatHistoryManager, MessageRole, ChatMessage


@dataclass
class ChatRequest:
    """èŠå¤©è¯·æ±‚æ•°æ®ç±» - JSONè¾“å…¥ç»“æ„"""
    request_id: str = field(default_factory=lambda: "req_" + uuid.uuid4().hex[:12]) # ä¸ºæ¯ä¸ªè¯·æ±‚ç”Ÿæˆå”¯ä¸€ID
    
    # æ–°å¢ï¼šç›´æ¥ä¼ å…¥æ•°æ®ï¼Œè€Œä¸æ˜¯é€šè¿‡config_idåŠ è½½
    character: Optional[Dict[str, Any]] = None
    persona: Optional[Dict[str, Any]] = None
    preset: Optional[Dict[str, Any]] = None
    additional_world_book: Optional[Dict[str, Any]] = None
    regex_rules: Optional[List[Dict[str, Any]]] = None
    
    # ä¿ç•™åŸæœ‰å­—æ®µ
    input: Optional[List[Dict[str, str]]] = None  # OpenAIæ ¼å¼çš„æ¶ˆæ¯æ•°ç»„ï¼ˆå®Œæ•´å¯¹è¯å†å²ï¼‰ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™è¿”å›è§’è‰²å¡çš„messageå­—æ®µå†…å®¹
    assistant_response: Optional[Dict[str, str]] = None  # å¯é€‰çš„assistantå“åº”ï¼Œå°†è¢«å¤„ç†åæ·»åŠ åˆ°æœ€ç»ˆè¾“å‡º
    output_formats: Optional[List[str]] = None  # æŒ‡å®šéœ€è¦çš„è¾“å‡ºæ ¼å¼åˆ—è¡¨
    views: Optional[List[str]] = None  # æŒ‡å®šéœ€è¦çš„è§†å›¾ç±»å‹åˆ—è¡¨
    
    @classmethod
    def from_json(cls, json_data: Union[str, Dict[str, Any]]) -> 'ChatRequest':
        """ä»JSONå­—ç¬¦ä¸²æˆ–å­—å…¸åˆ›å»ºChatRequestå¯¹è±¡"""
        if isinstance(json_data, str):
            import json
            data = json.loads(json_data)
        else:
            data = json_data
        
        return cls(
            request_id=data.get('request_id', "req_" + uuid.uuid4().hex[:12]),
            character=data.get('character'),
            persona=data.get('persona'),
            preset=data.get('preset'),
            additional_world_book=data.get('additional_world_book'),
            regex_rules=data.get('regex_rules'),
            input=data.get('input'),
            assistant_response=data.get('assistant_response'),
            output_formats=data.get('output_formats'),
            views=data.get('views')
        )

    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        import json
        return json.dumps({
            'request_id': self.request_id,
            'character': self.character,
            'persona': self.persona,
            'preset': self.preset,
            'additional_world_book': self.additional_world_book,
            'regex_rules': self.regex_rules,
            'input': self.input,
            'assistant_response': self.assistant_response,
            'output_formats': self.output_formats,
            'views': self.views
        }, ensure_ascii=False, indent=2)
    
    def validate(self) -> List[str]:
        """éªŒè¯è¾“å…¥æ•°æ®ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯åˆ—è¡¨"""
        errors = []
        
        if self.character is None and self.preset is None:
            errors.append("è‡³å°‘éœ€è¦æä¾› 'character' æˆ– 'preset' ä¸­çš„ä¸€ä¸ª")

        if self.input is not None:
            if not isinstance(self.input, list):
                errors.append("input å¿…é¡»æ˜¯åˆ—è¡¨æˆ–None")
            else:
                for i, msg in enumerate(self.input):
                    if not isinstance(msg, dict):
                        errors.append(f"input[{i}] å¿…é¡»æ˜¯å­—å…¸å¯¹è±¡")
                        continue
                    if 'role' not in msg or 'content' not in msg:
                        errors.append(f"input[{i}] å¿…é¡»åŒ…å« 'role' å’Œ 'content' å­—æ®µ")
                    if msg.get('role') not in ['system', 'user', 'assistant']:
                        errors.append(f"input[{i}] role å¿…é¡»æ˜¯ 'system', 'user' æˆ– 'assistant'")
                    if not isinstance(msg.get('content', ''), str):
                        errors.append(f"input[{i}] content å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
        
        # éªŒè¯assistant_responseå­—æ®µ
        if self.assistant_response is not None:
            if not isinstance(self.assistant_response, dict):
                errors.append("assistant_response å¿…é¡»æ˜¯å­—å…¸å¯¹è±¡æˆ–None")
            else:
                if 'role' not in self.assistant_response or 'content' not in self.assistant_response:
                    errors.append("assistant_response å¿…é¡»åŒ…å« 'role' å’Œ 'content' å­—æ®µ")
                if self.assistant_response.get('role') != 'assistant':
                    errors.append("assistant_response role å¿…é¡»æ˜¯ 'assistant'")
                if not isinstance(self.assistant_response.get('content', ''), str):
                    errors.append("assistant_response content å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
        
        if self.output_formats is not None:
            if not isinstance(self.output_formats, list):
                errors.append("output_formats å¿…é¡»æ˜¯åˆ—è¡¨æˆ–None")
            else:
                valid_formats = {'raw', 'processed', 'clean'}
                for fmt in self.output_formats:
                    if fmt not in valid_formats:
                        errors.append(f"æ— æ•ˆçš„è¾“å‡ºæ ¼å¼: '{fmt}'ï¼Œæ”¯æŒçš„æ ¼å¼: {valid_formats}")
                if len(self.output_formats) == 0:
                    errors.append("output_formats ä¸èƒ½ä¸ºç©ºåˆ—è¡¨")
        
        if self.views is not None:
            if not isinstance(self.views, list):
                errors.append("views å¿…é¡»æ˜¯åˆ—è¡¨æˆ–None")
            else:
                valid_views = {'user', 'assistant', 'all'}
                for view in self.views:
                    if view not in valid_views:
                        errors.append(f"æ— æ•ˆçš„è§†å›¾ç±»å‹: '{view}'ï¼Œæ”¯æŒçš„ç±»å‹: {valid_views}")
        
        return errors


@dataclass
class ChatResponse:
    """èŠå¤©å“åº”æ•°æ®ç±»"""
    source_id: str  # æ¥æºID
    
    # åº”ç”¨æ­£åˆ™åçš„ä¸‰ç§æ ¼å¼
    raw_prompt_with_regex: Optional[List[Dict[str, Any]]] = None  # æ ¼å¼1: åŸå§‹æç¤ºè¯+æ­£åˆ™
    processed_prompt_with_regex: Optional[List[Dict[str, Any]]] = None  # æ ¼å¼2: å¤„ç†åæç¤ºè¯+æ­£åˆ™
    clean_prompt_with_regex: Optional[List[Dict[str, str]]] = None  # æ ¼å¼3: æ ‡å‡†æ ¼å¼+æ­£åˆ™
    

    
    is_character_message: bool = False  # æ˜¯å¦ä¸ºè§’è‰²å¡æ¶ˆæ¯
    character_messages: Optional[Dict[str, List[Dict[str, str]]]] = None  # è§’è‰²å¡æ¶ˆæ¯çš„ä¸¤ä¸ªè§†å›¾ï¼ˆå®Œæ•´æ¶ˆæ¯å—æ ¼å¼ï¼‰
    processing_info: Dict[str, Any] = field(default_factory=dict)  # å¤„ç†ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
    request: Optional[ChatRequest] = None  # åŸå§‹è¯·æ±‚ä¿¡æ¯
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        import json
        
        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            'source_id': self.source_id,
            'is_character_message': self.is_character_message,
            'processing_info': self.processing_info
        }
        
        # ç®€åŒ–åçš„ç»Ÿä¸€å¤„ç†é€»è¾‘
        formats = {
            "raw_prompt": self.raw_prompt_with_regex,
            "processed_prompt": self.processed_prompt_with_regex,
            "clean_prompt": self.clean_prompt_with_regex
        }

        for key, prompt_data in formats.items():
            if prompt_data is None:
                continue
            
            # prompt_data åº”è¯¥å§‹ç»ˆæ˜¯ä¸€ä¸ªåŒ…å« user_view å’Œ assistant_view çš„å­—å…¸
            # æˆ–è€…åœ¨ raw æ ¼å¼ä¸‹æ˜¯ä¸€ä¸ªåˆ—è¡¨
            if isinstance(prompt_data, dict):
                 response_data[key] = {
                    'user_view': prompt_data.get('user_view', []),
                    'assistant_view': prompt_data.get('assistant_view', [])
                }
            else: # å…¼å®¹ raw æ ¼å¼çš„åˆ—è¡¨
                 response_data[key] = {
                    'user_view': prompt_data,
                    'assistant_view': prompt_data
                }
            

        # æ·»åŠ è§’è‰²å¡æ¶ˆæ¯
        if self.character_messages is not None:
            response_data['character_messages'] = self.character_messages
        
        # æ·»åŠ åŸå§‹è¯·æ±‚ä¿¡æ¯
        if self.request is not None:
            # ä½¿ç”¨ to_json æ–¹æ³•ï¼Œä½†å°†å…¶è½¬æ¢ä¸ºå­—å…¸
            response_data['request'] = json.loads(self.request.to_json())
        
        return json.dumps(response_data, ensure_ascii=False, indent=2)
    
    def _build_views_for_assistant_response(self, prompt_data):
        """ä¸ºassistant_responseå¤„ç†æ„å»ºuser_viewå’Œassistant_view
        
        Args:
            prompt_data: æç¤ºè¯æ•°æ®ï¼Œå¯èƒ½æ˜¯listæ ¼å¼æˆ–dictæ ¼å¼
            
        Returns:
            tuple: (user_view, assistant_view)
        """
        if isinstance(prompt_data, list):
            # å¦‚æœæ˜¯listæ ¼å¼ï¼Œéœ€è¦åˆ†ç¦»å‡ºåŸå§‹inputå’Œå¤„ç†åçš„assistant_response
            # å¹¶æ„å»ºæ­£ç¡®çš„user_viewå’Œassistant_view
            
            # æå–assistantå“åº”
            processed_assistant = self._extract_assistant_response_from_data(prompt_data)
            
            # æå–åŸå§‹inputï¼ˆé™¤äº†assistant_responseä¹‹å¤–çš„æ¶ˆæ¯ï¼‰
            original_input = []
            for msg in prompt_data:
                # æ£€æŸ¥æ˜¯å¦æ˜¯assistant_response_processingæ¶ˆæ¯
                source_identifiers = msg.get('_source_identifiers', [])
                is_assistant_processing = any(
                    isinstance(sid, str) and 'assistant_response_processing' in sid
                    for sid in source_identifiers
                )
                if not is_assistant_processing:
                    # æ„å»ºåŸå§‹inputæ¶ˆæ¯
                    original_input.append({
                        'role': msg.get('role', 'user'),
                        'content': msg.get('content', '')
                    })
            
            # ä½¿ç”¨_build_final_output_helperæ„å»ºè§†å›¾
            if processed_assistant:
                return self._build_final_output_helper(
                    original_input, processed_assistant, prompt_data
                )
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°processed_assistantï¼Œè¿”å›åŸå§‹æ•°æ®
                return prompt_data, prompt_data
        elif isinstance(prompt_data, dict) and 'user_view' in prompt_data and 'assistant_view' in prompt_data:
            # å¦‚æœå·²ç»æ˜¯dictæ ¼å¼ä¸”åŒ…å«ä¸¤ä¸ªè§†å›¾ï¼Œç›´æ¥è¿”å›
            return prompt_data['user_view'], prompt_data['assistant_view']
        else:
            # å…¶ä»–æƒ…å†µï¼Œè§†ä¸ºæ ‡å‡†æ ¼å¼
            return prompt_data, prompt_data
    
    def _extract_assistant_response_from_data(self, prompt_data):
        """ä»æç¤ºè¯æ•°æ®ä¸­æå–å¤„ç†åçš„assistantå“åº”"""
        for message in prompt_data:
            # æŸ¥æ‰¾åŒ…å«ç‰¹æ®Šæ ‡è¯†ç¬¦çš„æ¶ˆæ¯
            source_identifiers = message.get('_source_identifiers', [])
            for sid in source_identifiers:
                if isinstance(sid, str) and 'assistant_response_processing' in sid:
                    return {
                        'role': message.get('role', 'assistant'),
                        'content': message.get('content', '')
                    }
        return None
        
    def _build_final_output_helper(self, original_input, processed_assistant, clean_prompt):
        """æ„å»ºåŒ…å«å¤„ç†åassistantå“åº”çš„æœ€ç»ˆè¾“å‡º
        
        Args:
            original_input: åŸå§‹è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
            processed_assistant: å¤„ç†åçš„assistantå“åº”
            clean_prompt: cleanæ ¼å¼çš„å®Œæ•´æç¤ºè¯
            
        Returns:
            Tuple[ç”¨æˆ·è§†å›¾, Assistantè§†å›¾]
        """
        # ç”¨æˆ·è§†å›¾ï¼šåŸå§‹input + å¤„ç†åçš„assistantå“åº”ï¼ˆä¿ç•™å…ƒæ•°æ®ï¼‰
        user_view = []
        
        # æ·»åŠ åŸå§‹inputæ¶ˆæ¯ï¼ˆè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼‰
        for msg in original_input:
            user_view.append({
                'role': msg['role'],
                'content': msg['content'],
                '_source_types': ['conversation'],
                '_source_identifiers': ['input_history']
            })
        
        # æ·»åŠ å¤„ç†åçš„assistantå“åº”
        if processed_assistant:
            assistant_msg = {
                'role': processed_assistant['role'],
                'content': processed_assistant['content'],
                '_source_types': ['conversation'],
                '_source_identifiers': ['assistant_response_processed']  # æ ‡è®°ä¸ºå·²å¤„ç†çš„assistantå“åº”
            }
            user_view.append(assistant_msg)
        
        # AIè§†å›¾ï¼šåŸå§‹input + å¤„ç†åçš„assistantå“åº”ï¼ˆæ ‡å‡†OpenAIæ ¼å¼ï¼Œæ— å…ƒæ•°æ®ï¼‰
        assistant_view = []
        
        # æ·»åŠ åŸå§‹inputæ¶ˆæ¯
        for msg in original_input:
            assistant_view.append({
                'role': msg['role'],
                'content': msg['content']
            })
        
        # æ·»åŠ å¤„ç†åçš„assistantå“åº”
        if processed_assistant:
            assistant_view.append({
                'role': processed_assistant['role'],
                'content': processed_assistant['content']
            })
        
        return user_view, assistant_view


class ChatAPI:
    """ç»Ÿä¸€èŠå¤©APIæ¥å£"""
    
    def __init__(self, data_root: str = "data"):
        """
        åˆå§‹åŒ–APIæ¥å£
        
        Args:
            data_root: æ•°æ®æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸º"data"
        """
        self.data_root = data_root
        self.config_manager = create_config_manager(data_root)
    
    def chat_input_json(self, request_data: Union[str, Dict[str, Any], ChatRequest]) -> ChatResponse:
        """
        JSONè¾“å…¥èŠå¤©æ¥å£
        
        Args:
            request_data: å¯ä»¥æ˜¯ï¼š
                - JSONå­—ç¬¦ä¸²
                - å­—å…¸å¯¹è±¡
                - ChatRequestå¯¹è±¡
        
        Returns:
            ChatResponse: åŒ…å«æŒ‡å®šæ ¼å¼çš„æœ€ç»ˆæç¤ºè¯å’Œç›¸å…³ä¿¡æ¯çš„å“åº”å¯¹è±¡
        
        Raises:
            ValueError: å½“è¾“å…¥æ•°æ®æ— æ•ˆæ—¶
        """
        # è½¬æ¢ä¸ºChatRequestå¯¹è±¡
        if isinstance(request_data, ChatRequest):
            request = request_data
        else:
            try:
                request = ChatRequest.from_json(request_data)
            except Exception as e:
                raise ValueError(f"æ— æ•ˆçš„JSONè¾“å…¥: {e}")
        
        # éªŒè¯è¾“å…¥æ•°æ®
        validation_errors = request.validate()
        if validation_errors:
            raise ValueError(f"è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥: {'; '.join(validation_errors)}")
        
        # è°ƒç”¨åŸæœ‰çš„å¤„ç†æ–¹æ³•
        response = self._process_chat_request(request)
        
        # åœ¨å“åº”ä¸­ä¿å­˜åŸå§‹è¯·æ±‚ä¿¡æ¯
        response.request = request
        
        return response
    
    # chat_input æ–¹æ³•å°†è¢«åºŸå¼ƒæˆ–é‡æ„ï¼Œå› ä¸ºå®ƒä¾èµ– config_id
    # ä¸ºäº†ä¿æŒå…¼å®¹æ€§ï¼Œæˆ‘ä»¬å¯ä»¥æš‚æ—¶ä¿ç•™å®ƒï¼Œä½†å†…éƒ¨è°ƒç”¨ä¼šå¤±è´¥
    # æˆ–è€…ç›´æ¥ç§»é™¤å®ƒï¼Œå¼ºåˆ¶ç”¨æˆ·ä½¿ç”¨æ–°çš„ chat_input_json æ¥å£
    # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©æ³¨é‡Šæ‰å®ƒï¼Œé¼“åŠ±ä½¿ç”¨æ–°æ¥å£
    # def chat_input(...)
    
    def _process_chat_request(self, request: ChatRequest) -> ChatResponse:
        """
        ç»Ÿä¸€çš„èŠå¤©è¯·æ±‚å¤„ç†æ–¹æ³•
        
        Args:
            request: ChatRequestå¯¹è±¡
            
        Returns:
            ChatResponse: å¤„ç†ç»“æœ
        """
        try:
            # è®¾ç½®é»˜è®¤è¾“å‡ºæ ¼å¼
            output_formats = request.output_formats
            if output_formats is None:
                output_formats = ["raw", "processed", "clean"]  # é»˜è®¤è¿”å›æ‰€æœ‰æ ¼å¼
                
            # ç¡®ä¿è¾“å‡ºæ ¼å¼æœ‰æ•ˆï¼ˆä»…åŒ…å«åŸºç¡€ä¸‰ç§æ ¼å¼ï¼‰
            valid_formats = {"raw", "processed", "clean"}
            output_formats = [fmt for fmt in output_formats if fmt in valid_formats]
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„æ ¼å¼ï¼Œé»˜è®¤è¿”å›æ‰€æœ‰æ ¼å¼
            if not output_formats:
                output_formats = ["raw", "processed", "clean"]
            
            # 1. åŠ è½½æˆ–è·å–ChatHistoryManager
            manager = self._get_or_create_manager(request)
            
            # 2. å¤„ç†è¾“å…¥æ¶ˆæ¯æˆ–è¿”å›è§’è‰²å¡æ¶ˆæ¯
            if request.input is None:
                # æ²¡æœ‰è¾“å…¥æ¶ˆæ¯ï¼Œè¿”å›è§’è‰²å¡çš„messageå­—æ®µ
                response = self._handle_character_message(request.request_id, manager, output_formats)
            else:
                # æœ‰è¾“å…¥æ¶ˆæ¯ï¼Œå¤„ç†å®Œæ•´å¯¹è¯æµç¨‹
                response = self._handle_conversation_input(request.request_id, manager, request.input, request.assistant_response, output_formats)
            
            # ä¿å­˜åŸå§‹è¯·æ±‚ä¿¡æ¯
            response.request = request
            
            return response
                
        except Exception as e:
            # é”™è¯¯å¤„ç†
            return ChatResponse(
                source_id=request.request_id,
                processing_info={
                    "error": str(e),
                    "has_input": request.input is not None,
                    "input_message_count": len(request.input) if request.input else 0
                },
                request=request
            )
    
    def _get_or_create_manager(self, request: ChatRequest) -> ChatHistoryManager:
        """ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºä¸€ä¸ªæ–°çš„ç®¡ç†å™¨å®ä¾‹"""
        return self._create_manager_from_request(request)

    def _create_manager_from_request(self, request: ChatRequest) -> ChatHistoryManager:
        """æ ¹æ®è¯·æ±‚ä¸­çš„å†…è”æ•°æ®åˆ›å»ºChatHistoryManager"""
        from .services.regex_rule_manager import RegexRuleManager
        from .services.chat_history_manager import create_chat_manager

        # åŠ è½½æ­£åˆ™è§„åˆ™ï¼ˆå¦‚æœæœ‰ï¼‰
        regex_rule_manager = None
        if request.regex_rules:
            regex_rule_manager = RegexRuleManager()
            # æ³¨æ„ï¼šRegexRuleManagerçš„é»˜è®¤è¡Œä¸ºæ˜¯åŠ è½½ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ–¹æ³•æ¥ä»æ•°æ®è€Œä¸æ˜¯æ–‡ä»¶åŠ è½½è§„åˆ™
            # ä¸´æ—¶æ–¹æ¡ˆï¼šç›´æ¥ä½¿ç”¨æ•°æ®
            regex_rule_manager.load_rules_from_data(request.regex_rules)

        # åˆ›å»ºåŸºç¡€ç®¡ç†å™¨
        manager = create_chat_manager(
            character_data=request.character or {},
            preset_data=request.preset or {},
            persona_data=request.persona or {},
            regex_rule_manager=regex_rule_manager
        )

        # åŠ è½½é€šç”¨ä¸–ç•Œä¹¦ï¼ˆå¦‚æœæœ‰ï¼‰
        if request.additional_world_book:
            # ç°åœ¨ ConfigManager ä»ç„¶ç”¨äºè¾…åŠ©åŠŸèƒ½ï¼Œæ¯”å¦‚åˆå¹¶ä¸–ç•Œä¹¦
            # æ³¨æ„ï¼šè¿™é‡Œçš„ config_manager å®ä¾‹æ˜¯åœ¨ ChatAPI åˆå§‹åŒ–æ—¶åˆ›å»ºçš„
            self.config_manager.merge_additional_world_book(manager, {"world_book": request.additional_world_book})
            
        return manager
    
    def _handle_character_message(self, request_id: str, manager: ChatHistoryManager, output_formats: List[str]) -> ChatResponse:
        """å¤„ç†è§’è‰²å¡æ¶ˆæ¯ï¼ˆæ— ç”¨æˆ·è¾“å…¥ï¼‰"""
        
        # è·å–è§’è‰²å¡çš„åŸå§‹messageå­—æ®µ
        raw_character_messages = []
        if manager.character_data and "message" in manager.character_data:
            message_data = manager.character_data["message"]
            if isinstance(message_data, list):
                raw_character_messages = message_data
            elif isinstance(message_data, str):
                raw_character_messages = [message_data]
        
        # æ„å»ºç»è¿‡å®Œæ•´å¤„ç†çš„character_messagesï¼ˆåŒ…å«ä¸Šä¸‹æ–‡ã€å®å’Œæ­£åˆ™å¤„ç†ï¼‰
        processed_character_messages = self._build_character_messages_with_context(
            request_id, manager, raw_character_messages
        )
        
        # æ— è®ºç”¨æˆ·è¯·æ±‚å“ªç§æ ¼å¼ï¼Œæˆ‘ä»¬éƒ½éœ€è¦ç”Ÿæˆç”¨æˆ·è§†å›¾å’ŒAIè§†å›¾
        # è°ƒç”¨ build_final_prompt ä¸€æ¬¡ï¼Œå®ƒä¼šå¤„ç†æ‰€æœ‰è§†å›¾
        manager.build_final_prompt(view_type="all") # "all" åªæ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œå› ä¸ºå†…éƒ¨ä¼šæ„å»ºæ‰€æœ‰è§†å›¾
        
        # ä» prompt_builder è·å–ä¸¤ä¸ªè§†å›¾çš„ç»“æœ
        pb = manager.prompt_builder
        processed_user_view = pb.processed_prompt_user_view
        processed_assistant_view = pb.processed_prompt_assistant_view
        clean_user_view = pb.clean_prompt_user_view
        clean_assistant_view = pb.clean_prompt_assistant_view
        raw_view = pb.raw_prompt # Raw è§†å›¾ä¸¤ä¸ªè§†è§’ç›¸åŒ

        return ChatResponse(
            source_id=request_id,
            raw_prompt_with_regex=raw_view if "raw" in output_formats else None,
            processed_prompt_with_regex={
                "user_view": processed_user_view,
                "assistant_view": processed_assistant_view
            },
            clean_prompt_with_regex={
                "user_view": clean_user_view,
                "assistant_view": clean_assistant_view
            },
            is_character_message=True,
            character_messages=processed_character_messages,
            processing_info={
                "config_loaded": True,
                "message_count": len(raw_character_messages),
                "character_messages_processed": True,
                "output_formats": output_formats,
                "prompt_blocks_raw": len(raw_view) if raw_view else 0,
                "prompt_blocks_processed_user": len(processed_user_view),
                "prompt_blocks_processed_assistant": len(processed_assistant_view),
                "prompt_blocks_clean_user": len(clean_user_view),
                "prompt_blocks_clean_assistant": len(clean_assistant_view)
            }
        )
    
    def _handle_conversation_input(self, request_id: str, manager: ChatHistoryManager, input_messages: List[Dict[str, str]], assistant_response: Optional[Dict[str, str]], output_formats: List[str]) -> ChatResponse:
        """å¤„ç†å®Œæ•´å¯¹è¯å†å²è¾“å…¥"""
        
        # å¦‚æœæ²¡æœ‰assistant_responseï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
        if assistant_response is None:
            return self._handle_standard_conversation(request_id, manager, input_messages, output_formats)
        
        # å¦‚æœæœ‰assistant_responseï¼Œä½¿ç”¨ç‰¹æ®Šå¤„ç†é€»è¾‘
        return self._handle_conversation_with_assistant_response(request_id, manager, input_messages, assistant_response, output_formats)
    
    def _handle_standard_conversation(self, request_id: str, manager: ChatHistoryManager, input_messages: List[Dict[str, str]], output_formats: List[str]) -> ChatResponse:
        """å¤„ç†æ ‡å‡†å¯¹è¯ï¼ˆæ— assistant_responseï¼‰"""
        
        # ğŸŒŸ å°†OpenAIæ ¼å¼çš„å¯¹è¯å†å²è½¬æ¢ä¸ºå†…éƒ¨ChatMessageæ ¼å¼
        converted_history = []
        for msg in input_messages:
            role = MessageRole(msg['role']) if msg['role'] in ['system', 'user', 'assistant'] else MessageRole.USER
            chat_msg = ChatMessage(
                role=role,
                content=msg['content'],
                metadata={'source': 'input_history'}
            )
            converted_history.append(chat_msg)
        
        # è®¾ç½®ä¸ºmanagerçš„åŸºå‡†å†å²
        manager.chat_history = converted_history
        
        # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ç”¨äºæ¡ä»¶ä¸–ç•Œä¹¦è§¦å‘
        last_user_message = None
        for msg in reversed(input_messages):
            if msg['role'] == 'user':
                last_user_message = msg['content']
                break
        
        # æ£€æŸ¥æ¡ä»¶ä¸–ç•Œä¹¦è§¦å‘ï¼ˆåŸºäºæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
        if last_user_message:
            manager._check_conditional_world_book(last_user_message)
        
        # æ— è®ºç”¨æˆ·è¯·æ±‚å“ªç§æ ¼å¼ï¼Œæˆ‘ä»¬éƒ½éœ€è¦ç”Ÿæˆç”¨æˆ·è§†å›¾å’ŒAIè§†å›¾
        # è°ƒç”¨ build_final_prompt ä¸€æ¬¡ï¼Œå®ƒä¼šå¤„ç†æ‰€æœ‰è§†å›¾
        manager.build_final_prompt(view_type="all")

        # ä» prompt_builder è·å–ä¸¤ä¸ªè§†å›¾çš„ç»“æœ
        pb = manager.prompt_builder
        processed_user_view = pb.processed_prompt_user_view
        processed_assistant_view = pb.processed_prompt_assistant_view
        clean_user_view = pb.clean_prompt_user_view
        clean_assistant_view = pb.clean_prompt_assistant_view
        raw_view = pb.raw_prompt

        return ChatResponse(
            source_id=request_id,
            raw_prompt_with_regex=raw_view if "raw" in output_formats else None,
            processed_prompt_with_regex={
                "user_view": processed_user_view,
                "assistant_view": processed_assistant_view
            },
            clean_prompt_with_regex={
                "user_view": clean_user_view,
                "assistant_view": clean_assistant_view
            },
            is_character_message=False,
            processing_info={
                "input_message_count": len(input_messages),
                "total_messages": len(manager.chat_history),
                "triggered_entries": len(manager.triggered_entries),
                "output_formats": output_formats,
                "prompt_blocks_raw": len(raw_view) if raw_view else 0,
                "prompt_blocks_processed_user": len(processed_user_view),
                "prompt_blocks_processed_assistant": len(processed_assistant_view),
                "prompt_blocks_clean_user": len(clean_user_view),
                "prompt_blocks_clean_assistant": len(clean_assistant_view),
                "last_user_message": last_user_message
            }
        )
    
    def _handle_conversation_with_assistant_response(self, request_id: str, manager: ChatHistoryManager, input_messages: List[Dict[str, str]], assistant_response: Dict[str, str], output_formats: List[str]) -> ChatResponse:
        """å¤„ç†åŒ…å«assistant_responseçš„å¯¹è¯ï¼Œæ ¹æ®output_formatsè¿”å›ä¸åŒçš„ç»“æœ"""
        
        # ğŸŒŸ ä¸ºä¸åŒçš„output_formatsç”Ÿæˆä¸åŒçš„ç»“æœ
        result_data = {}
        # å¤‡ä»½åŸå§‹å¯¹è¯å†å²ï¼Œé¿å…ä¿å­˜ä¸´æ—¶assistant_response
        original_history = list(manager.chat_history)
        
        # ===== å¤„ç† RAW æ ¼å¼ =====
        if "raw" in output_formats:
            # RAW: åªæŠŠassistant_responseåŸæ ·åŠ åˆ°inputæœ«å°¾ï¼Œä¸è¿›è¡Œä»»ä½•å¤„ç†
            raw_result = self._build_raw_with_assistant_response(input_messages, assistant_response)
            result_data["raw"] = raw_result
        
        # ===== å¤„ç† PROCESSED æ ¼å¼ =====
        if "processed" in output_formats:
            # PROCESSED: å¯¹assistant_responseè¿›è¡Œå®Œæ•´å¤„ç†ï¼Œè¿”å›å®Œæ•´çš„æç¤ºè¯å¤„ç†ç»“æœ
            processed_result = self._build_processed_with_assistant_response(
                request_id, manager, input_messages, assistant_response
            )
            result_data["processed"] = processed_result
        
        # ===== å¤„ç† CLEAN æ ¼å¼ =====
        if "clean" in output_formats:
            # CLEAN: æå–å¤„ç†åçš„assistant_responseï¼Œæ‹¼æ¥åˆ°åŸå§‹inputæœ«å°¾
            clean_result = self._build_clean_with_assistant_response(
                request_id, manager, input_messages, assistant_response
            )
            result_data["clean"] = clean_result
        
        return ChatResponse(
            source_id=request_id,
            raw_prompt_with_regex=result_data.get("raw"),
            processed_prompt_with_regex=result_data.get("processed"),
            clean_prompt_with_regex=result_data.get("clean"),

            is_character_message=False,
            processing_info={
                "input_message_count": len(input_messages),
                "assistant_response_processed": True,
                "output_formats": output_formats,
                "formats_generated": list(result_data.keys())
            }
        )
    
    def _build_raw_with_assistant_response(self, input_messages: List[Dict[str, str]], assistant_response: Dict[str, str]) -> List[Dict[str, str]]:
        """æ„å»ºRAWæ ¼å¼ï¼šåŸå§‹input + æœªå¤„ç†çš„assistant_response"""
        result = input_messages.copy()
        result.append({
            "role": assistant_response["role"],
            "content": assistant_response["content"]  # åŸå§‹å†…å®¹ï¼Œæœªå¤„ç†å®å’Œæ­£åˆ™
        })
        return result
    
    def _build_processed_with_assistant_response(self, request_id: str, manager: ChatHistoryManager, input_messages: List[Dict[str, str]], assistant_response: Dict[str, str]) -> List[Dict[str, Any]]:
        """æ„å»ºPROCESSEDæ ¼å¼ï¼šå®Œæ•´çš„æç¤ºè¯å¤„ç†ç»“æœ"""
        
        # ğŸŒŸ æ­¥éª¤1ï¼šå°†assistant_responseæ·»åŠ åˆ°inputæœ«å°¾ï¼Œå¹¶æ·»åŠ ç‰¹æ®Šæ ‡è¯†
        extended_input = input_messages.copy()
        assistant_msg_with_marker = assistant_response.copy()
        assistant_msg_with_marker['_special_source_id'] = 'assistant_response_processing'
        extended_input.append(assistant_msg_with_marker)
        
        # ğŸŒŸ æ­¥éª¤2ï¼šå°†æ‰©å±•åçš„inputè½¬æ¢ä¸ºChatMessageæ ¼å¼
        converted_history = []
        for msg in extended_input:
            role = MessageRole(msg['role']) if msg['role'] in ['system', 'user', 'assistant'] else MessageRole.USER
            chat_msg = ChatMessage(role=role, content=msg['content'])  # ğŸ”§ ä¿®å¤ï¼šè®¾ç½®å‘åå…¼å®¹çš„contentå­—æ®µ
            
            # ä¸ºç‰¹æ®Šçš„assistantå“åº”åˆ›å»ºChatMessageï¼Œæ·»åŠ ç‰¹æ®Šsource_identifiers
            if msg.get('_special_source_id') == 'assistant_response_processing':
                chat_msg.add_content_part(
                    content=msg['content'],
                    source_type='conversation',
                    source_id='assistant_response_processing',  # ç‰¹æ®Šæ ‡è¯†ç¬¦
                    source_name='Assistant Response Processing'
                )
            else:
                # ç»Ÿä¸€ä½¿ç”¨add_content_partæ–¹æ³•ï¼Œç¡®ä¿ä¸€è‡´æ€§
                chat_msg.add_content_part(
                    content=msg['content'],
                    source_type='conversation',
                    source_id=f"input_{role.value}",  # æ ¹æ®è§’è‰²ç”Ÿæˆsource_id
                    source_name='Input History'
                )
            
            converted_history.append(chat_msg)
        
        # è®¾ç½®ä¸ºmanagerçš„åŸºå‡†å†å²
        manager.chat_history = converted_history
        
        # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ç”¨äºæ¡ä»¶ä¸–ç•Œä¹¦è§¦å‘
        last_user_message = None
        for msg in reversed(input_messages):
            if msg['role'] == 'user':
                last_user_message = msg['content']
                break
        
        # æ£€æŸ¥æ¡ä»¶ä¸–ç•Œä¹¦è§¦å‘
        if last_user_message:
            manager._check_conditional_world_book(last_user_message)
        
        # ğŸŒŸ æ­¥éª¤3ï¼šè¿”å›å®Œæ•´çš„processedæ ¼å¼ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºã€ä¸–ç•Œä¹¦ç­‰ï¼‰
        # ä½¿ç”¨æ–°çš„ä¸‰é˜¶æ®µç®¡çº¿çš„"processed"è§†å›¾ï¼Œå†…éƒ¨å·²åŒ…å«æ­£åˆ™é˜¶æ®µ
        return manager.to_processed_openai_format()
    
    def _build_clean_with_assistant_response(self, request_id: str, manager: ChatHistoryManager, input_messages: List[Dict[str, str]], assistant_response: Dict[str, str]) -> List[Dict[str, str]]:
        """æ„å»ºCLEANæ ¼å¼ï¼šåŸå§‹input + æå–å‡ºçš„å¤„ç†åassistant_response"""
        
        # å…ˆè·å–processedæ ¼å¼çš„å®Œæ•´ç»“æœ
        processed_result = self._build_processed_with_assistant_response(
            request_id, manager, input_messages, assistant_response
        )
        
        # ä»processedç»“æœä¸­æå–å¤„ç†åçš„assistantå“åº”
        processed_assistant_response = self._extract_processed_assistant_response(processed_result)
        
        # æ„å»ºcleanæ ¼å¼ï¼šåŸå§‹input + å¤„ç†åçš„assistantå“åº”ï¼ˆæ ‡å‡†OpenAIæ ¼å¼ï¼Œæ— å…ƒæ•°æ®ï¼‰
        clean_result = []
        
        # æ·»åŠ åŸå§‹inputæ¶ˆæ¯
        for msg in input_messages:
            clean_result.append({
                'role': msg['role'],
                'content': msg['content']
            })
        
        # æ·»åŠ å¤„ç†åçš„assistantå“åº”
        if processed_assistant_response:
            # æ·»åŠ å¸¦æœ‰æ ‡è®°çš„processed_assistant_responseï¼Œä¿ç•™assistant_response_processingæ ‡è®°
            # è¿™æ˜¯æ ¹æœ¬æ€§è§£å†³æ–¹æ¡ˆçš„å…³é”®ï¼šä¿ç•™æ ‡è®°ä¿¡æ¯ä»¥ä¾¿åç»­å¤„ç†èƒ½æ­£ç¡®è¯†åˆ«
            clean_result.append({
                'role': processed_assistant_response['role'],
                'content': processed_assistant_response['content'],
                # æ·»åŠ æ ‡è®°ä¿¡æ¯ï¼Œè¿™æ ·åœ¨_build_views_for_assistant_responseä¸­èƒ½æ­£ç¡®è¯†åˆ«
                '_source_types': ['conversation'],
                '_source_identifiers': ['assistant_response_processed']
            })
        
        return clean_result
    
    def _extract_processed_assistant_response(self, processed_prompt: List[Dict[str, Any]]) -> Optional[Dict[str, str]]:
        """ä»processedæ ¼å¼çš„è¾“å‡ºä¸­æå–å¤„ç†åçš„assistantå“åº”"""
        for message in processed_prompt:
            # æŸ¥æ‰¾åŒ…å«ç‰¹æ®Šæ ‡è¯†ç¬¦çš„æ¶ˆæ¯
            source_identifiers = message.get('_source_identifiers', [])
            for sid in source_identifiers:
                if isinstance(sid, str) and 'assistant_response_processing' in sid:
                    return {
                        'role': message.get('role', 'assistant'),
                        'content': message.get('content', '')
                    }
        return None
    
    def _build_final_output_with_processed_assistant(self, original_input: List[Dict[str, str]], processed_assistant: Optional[Dict[str, str]], clean_prompt: List[Dict[str, str]]) -> Tuple[List[Dict[str, Any]], List[Dict[str, str]]]:
        """æ„å»ºåŒ…å«å¤„ç†åassistantå“åº”çš„æœ€ç»ˆè¾“å‡º
        
        Args:
            original_input: åŸå§‹è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
            processed_assistant: å¤„ç†åçš„assistantå“åº”
            clean_prompt: cleanæ ¼å¼çš„å®Œæ•´æç¤ºè¯
            
        Returns:
            Tuple[ç”¨æˆ·è§†å›¾, Assistantè§†å›¾]
        """
        # ç”¨æˆ·è§†å›¾ï¼šåŸå§‹input + å¤„ç†åçš„assistantå“åº”ï¼ˆä¿ç•™å…ƒæ•°æ®ï¼‰
        user_view = []
        
        # æ·»åŠ åŸå§‹inputæ¶ˆæ¯ï¼ˆè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼‰
        for msg in original_input:
            user_view.append({
                'role': msg['role'],
                'content': msg['content'],
                '_source_types': ['conversation'],
                '_source_identifiers': ['input_history']
            })
        
        # æ·»åŠ å¤„ç†åçš„assistantå“åº”
        if processed_assistant:
            assistant_msg = {
                'role': processed_assistant['role'],
                'content': processed_assistant['content'],
                '_source_types': ['conversation'],
                '_source_identifiers': ['assistant_response_processed']  # æ ‡è®°ä¸ºå·²å¤„ç†çš„assistantå“åº”
            }
            user_view.append(assistant_msg)
        
        # AIè§†å›¾ï¼šåŸå§‹input + å¤„ç†åçš„assistantå“åº”ï¼ˆæ ‡å‡†OpenAIæ ¼å¼ï¼Œæ— å…ƒæ•°æ®ï¼‰
        assistant_view = []
        
        # æ·»åŠ åŸå§‹inputæ¶ˆæ¯
        for msg in original_input:
            assistant_view.append({
                'role': msg['role'],
                'content': msg['content']
            })
        
        # æ·»åŠ å¤„ç†åçš„assistantå“åº”
        if processed_assistant:
            assistant_view.append({
                'role': processed_assistant['role'],
                'content': processed_assistant['content']
            })
        
        return user_view, assistant_view
    
    def add_assistant_message(self, session_id: str, assistant_message: str) -> bool:
        """(å·²åºŸå¼ƒ)"""
        print("âš ï¸ add_assistant_message() is deprecated in stateless mode.")
        return False
    
    def get_conversation_history(self, session_id: str) -> List[Dict[str, Any]]:
        """(å·²åºŸå¼ƒ)"""
        print("âš ï¸ get_conversation_history() is deprecated in stateless mode.")
        return []
    
    def clear_conversation(self, session_id: str) -> bool:
        """(å·²åºŸå¼ƒ)"""
        print("âš ï¸ clear_conversation() is deprecated in stateless mode.")
        return False
    
    def list_available_configs(self) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®
        
        Returns:
            List[Dict]: é…ç½®ä¿¡æ¯åˆ—è¡¨
        """
        try:
            configs = self.config_manager.list_configs()
            return [
                {
                    "config_id": config.config_id,
                    "name": config.name,
                    "description": config.description,
                    "components": config.components,
                    "tags": config.tags,
                    "last_used": config.last_used
                }
                for config in configs
            ]
        except Exception as e:
            print(f"âš ï¸ åˆ—å‡ºé…ç½®å¤±è´¥: {e}")
            return []
    
    def _build_character_messages_with_context(self, request_id: str, manager: ChatHistoryManager, raw_character_messages: List[str]) -> Dict[str, List[Dict[str, str]]]:
        """ä¸ºcharacter_messagesæ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„user_viewå’Œassistant_view
        
        Args:
            request_id: è¯·æ±‚ID
            manager: ChatHistoryManagerå®ä¾‹
            raw_character_messages: åŸå§‹è§’è‰²æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            DictåŒ…å«user_viewå’Œassistant_viewä¸¤ä¸ªé”®ï¼Œæ¯ä¸ªé”®å¯¹åº”å¤„ç†åçš„å®Œæ•´æ¶ˆæ¯å—åˆ—è¡¨
        """
        user_view_messages = []
        assistant_view_messages = []
        
        for raw_message in raw_character_messages:
            # ä¸ºæ¯ä¸ªcharacter messageåˆ›å»ºç‰¹æ®Šçš„ChatMessage
            character_msg = ChatMessage(role=MessageRole.ASSISTANT)
            character_msg.add_content_part(
                content=raw_message,
                source_type='conversation', 
                source_id='character_message_processing',
                source_name='Character Message Processing'
            )
            
            # å¤‡ä»½åŸå§‹å¯¹è¯å†å²
            original_history = list(manager.chat_history)
            
            try:
                # å°†character messageè®¾ç½®ä¸ºä¸´æ—¶å†å²è®°å½•
                manager.chat_history = [character_msg]
                
                # é€šè¿‡PromptBuilderæ„å»ºåŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡çš„æç¤ºè¯
                processed_prompt = manager.build_final_prompt(view_type="processed_with_regex")
                clean_prompt = manager.build_final_prompt(view_type="clean_with_regex")
                
                # ä»processedå’Œcleanæ ¼å¼ä¸­æå–å¤„ç†åçš„character message
                processed_char_msg = self._extract_character_message_from_prompt(processed_prompt)
                clean_char_msg = self._extract_character_message_from_prompt(clean_prompt)
                
                # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯å—æ ¼å¼
                if processed_char_msg:
                    user_view_messages.append({
                        'role': 'assistant',
                        'content': processed_char_msg
                    })
                else:
                    # å‡ºé”™æ—¶ä½¿ç”¨åŸå§‹æ¶ˆæ¯
                    user_view_messages.append({
                        'role': 'assistant',
                        'content': raw_message
                    })
                    
                if clean_char_msg:
                    assistant_view_messages.append({
                        'role': 'assistant',
                        'content': clean_char_msg
                    })
                else:
                    # å‡ºé”™æ—¶ä½¿ç”¨åŸå§‹æ¶ˆæ¯
                    assistant_view_messages.append({
                        'role': 'assistant',
                        'content': raw_message
                    })
                    
            except Exception as e:
                print(f"âš ï¸ å¤„ç†character messageæ—¶å‡ºé”™: {e}")
                # å‡ºé”™æ—¶ä½¿ç”¨åŸå§‹æ¶ˆæ¯å—æ ¼å¼
                user_view_messages.append({
                    'role': 'assistant',
                    'content': raw_message
                })
                assistant_view_messages.append({
                    'role': 'assistant',
                    'content': raw_message
                })
            finally:
                # æ¢å¤åŸå§‹å¯¹è¯å†å²
                manager.chat_history = original_history
        
        return {
            'user_view': user_view_messages,
            'assistant_view': assistant_view_messages
        }
    
    def _extract_character_message_from_prompt(self, prompt_data: List[Dict[str, Any]]) -> Optional[str]:
        """ä»æç¤ºè¯æ•°æ®ä¸­æå–å¤„ç†åçš„character message"""
        for message in prompt_data:
            # æŸ¥æ‰¾åŒ…å«ç‰¹æ®Šæ ‡è¯†ç¬¦çš„æ¶ˆæ¯
            source_identifiers = message.get('_source_identifiers', [])
            for sid in source_identifiers:
                if isinstance(sid, str) and 'character_message_processing' in sid:
                    return message.get('content', '')
        return None


# ä¾¿æ·å‡½æ•°
def create_chat_api(data_root: str = "data") -> ChatAPI:
    """åˆ›å»ºèŠå¤©APIå®ä¾‹"""
    return ChatAPI(data_root)


# ç®€åŒ–çš„å‡½æ•°æ¥å£ (chat) å·²è¢«åºŸå¼ƒï¼Œå› ä¸ºå®ƒä¾èµ– config_id

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import json

    # åˆ›å»ºAPIå®ä¾‹
    api = create_chat_api()
    
    # åˆ—å‡ºå¯ç”¨é…ç½®ï¼ˆè¿™ä¸ªåŠŸèƒ½ä»ç„¶æœ‰ç”¨ï¼Œå¯ä»¥ç”¨äºè·å–æ¨¡æ¿æ•°æ®ï¼‰
    configs = api.list_available_configs()
    print("å¯ç”¨é…ç½®:", configs)
    
    # ç¤ºä¾‹å¯¹è¯
    
    # --- æ„å»ºæ–°çš„è¯·æ±‚ ---
    # å‡è®¾æˆ‘ä»¬ä»æ–‡ä»¶åŠ è½½æ•°æ®æ¥æ„å»ºè¯·æ±‚
    # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™äº›æ•°æ®å°†ç”±å®¢æˆ·ç«¯ç›´æ¥æä¾›
    with open("data/characters/test_character.simplified.json", "r", encoding="utf-8") as f:
        char_data = json.load(f)
    with open("data/presets/test_preset.simplified.json", "r", encoding="utf-8") as f:
        preset_data = json.load(f)
    with open("data/world_books/test_world.json", "r", encoding="utf-8") as f:
        world_data = json.load(f)
        
    request_data = {
        "character": char_data,
        "preset": preset_data,
        "additional_world_book": world_data,
        "input": [{"role": "user", "content": "ä½ å¥½ï¼"}],
        "output_formats": ["clean", "processed"]
    }

    # 1. å‘é€è¯·æ±‚
    print("\n=== ç”¨æˆ·å¯¹è¯ (æ–°æ¥å£) ===")
    response = api.chat_input_json(request_data)
    
    if response.clean_prompt_with_regex:
        print(f"æœ€ç»ˆæç¤ºè¯é•¿åº¦ (clean): {len(response.clean_prompt_with_regex)}")
        # print(json.dumps(response.clean_prompt_with_regex, ensure_ascii=False, indent=2))
    
    if response.processed_prompt_with_regex:
        print(f"æœ€ç»ˆæç¤ºè¯é•¿åº¦ (processed): {len(response.processed_prompt_with_regex)}")

    print(f"å¤„ç†ä¿¡æ¯: {response.processing_info}")
    
    # 2. æ·»åŠ AIå›å¤
    # api.add_assistant_message(session_id, "ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼")
    
    # 3. æŸ¥çœ‹å¯¹è¯å†å²
    # history = api.get_conversation_history(session_id)
    # print(f"\nå¯¹è¯å†å²æ¶ˆæ¯æ•°: {len(history)}")
